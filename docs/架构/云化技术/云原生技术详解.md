# NSRS号卡资源管理系统 - 云原生技术详解

## 概述

云原生技术是NSRS号卡资源管理系统现代化架构的核心基础，通过Kubernetes容器编排、Docker容器化、Service Mesh服务网格等技术，实现应用的弹性扩展、高可用部署和智能运维，为电信级业务提供稳定可靠的技术支撑。

## 云原生核心概念

### 容器编排策略枚举

```java
/**
 * 容器编排策略枚举
 * 定义不同的容器编排和调度策略
 */
public enum ContainerOrchestrationStrategy {
    /**
     * 滚动更新
     */
    ROLLING_UPDATE("ROLLING_UPDATE", "滚动更新", "RollingUpdate"),
    
    /**
     * 蓝绿部署
     */
    BLUE_GREEN("BLUE_GREEN", "蓝绿部署", "BlueGreen"),
    
    /**
     * 金丝雀发布
     */
    CANARY("CANARY", "金丝雀发布", "Canary"),
    
    /**
     * 重建部署
     */
    RECREATE("RECREATE", "重建部署", "Recreate");
    
    private final String code;
    private final String description;
    private final String k8sStrategy;
    
    ContainerOrchestrationStrategy(String code, String description, String k8sStrategy) {
        this.code = code;
        this.description = description;
        this.k8sStrategy = k8sStrategy;
    }
    
    // getters...
}
```

### 服务网格组件枚举

```java
/**
 * 服务网格组件枚举
 * 定义Service Mesh架构中的核心组件
 */
public enum ServiceMeshComponent {
    /**
     * 数据平面 - Envoy代理
     */
    DATA_PLANE("DATA_PLANE", "数据平面", "envoy"),
    
    /**
     * 控制平面 - Istiod
     */
    CONTROL_PLANE("CONTROL_PLANE", "控制平面", "istiod"),
    
    /**
     * 网关 - Istio Gateway
     */
    GATEWAY("GATEWAY", "网关", "istio-gateway"),
    
    /**
     * 可观测性 - Jaeger
     */
    OBSERVABILITY("OBSERVABILITY", "可观测性", "jaeger"),
    
    /**
     * 监控 - Prometheus
     */
    MONITORING("MONITORING", "监控", "prometheus"),
    
    /**
     * 可视化 - Kiali
     */
    VISUALIZATION("VISUALIZATION", "可视化", "kiali");
    
    private final String code;
    private final String description;
    private final String component;
    
    ServiceMeshComponent(String code, String description, String component) {
        this.code = code;
        this.description = description;
        this.component = component;
    }
    
    // getters...
}
```

## Kubernetes资源管理

### Kubernetes资源实体

```java
/**
 * Kubernetes资源实体
 * 定义K8s集群中的资源对象
 */
@Entity
@Table(name = "k8s_resource")
public class KubernetesResource {
    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    private Long id;
    
    /**
     * 资源名称
     */
    @Column(name = "resource_name", nullable = false, length = 100)
    private String resourceName;
    
    /**
     * 资源类型
     */
    @Enumerated(EnumType.STRING)
    @Column(name = "resource_type", nullable = false)
    private KubernetesResourceType resourceType;
    
    /**
     * 命名空间
     */
    @Column(name = "namespace", nullable = false, length = 100)
    private String namespace;
    
    /**
     * 集群名称
     */
    @Column(name = "cluster_name", nullable = false, length = 100)
    private String clusterName;
    
    /**
     * 资源配置（YAML格式）
     */
    @Column(name = "resource_config", columnDefinition = "TEXT")
    private String resourceConfig;
    
    /**
     * 资源状态
     */
    @Enumerated(EnumType.STRING)
    @Column(name = "resource_status", nullable = false)
    private KubernetesResourceStatus resourceStatus;
    
    /**
     * 标签（JSON格式）
     */
    @Column(name = "labels", columnDefinition = "TEXT")
    private String labels;
    
    /**
     * 注解（JSON格式）
     */
    @Column(name = "annotations", columnDefinition = "TEXT")
    private String annotations;
    
    /**
     * 创建时间
     */
    @Column(name = "created_at")
    private LocalDateTime createdAt;
    
    /**
     * 更新时间
     */
    @Column(name = "updated_at")
    private LocalDateTime updatedAt;
    
    // constructors, getters, setters...
}
```

### Kubernetes资源类型枚举

```java
/**
 * Kubernetes资源类型枚举
 */
public enum KubernetesResourceType {
    /**
     * 部署
     */
    DEPLOYMENT("Deployment", "部署", "apps/v1"),
    
    /**
     * 服务
     */
    SERVICE("Service", "服务", "v1"),
    
    /**
     * 配置映射
     */
    CONFIG_MAP("ConfigMap", "配置映射", "v1"),
    
    /**
     * 密钥
     */
    SECRET("Secret", "密钥", "v1"),
    
    /**
     * 入口
     */
    INGRESS("Ingress", "入口", "networking.k8s.io/v1"),
    
    /**
     * 持久卷声明
     */
    PERSISTENT_VOLUME_CLAIM("PersistentVolumeClaim", "持久卷声明", "v1"),
    
    /**
     * 水平Pod自动扩缩器
     */
    HORIZONTAL_POD_AUTOSCALER("HorizontalPodAutoscaler", "水平Pod自动扩缩器", "autoscaling/v2"),
    
    /**
     * 网络策略
     */
    NETWORK_POLICY("NetworkPolicy", "网络策略", "networking.k8s.io/v1"),
    
    /**
     * 服务账户
     */
    SERVICE_ACCOUNT("ServiceAccount", "服务账户", "v1"),
    
    /**
     * 角色绑定
     */
    ROLE_BINDING("RoleBinding", "角色绑定", "rbac.authorization.k8s.io/v1");
    
    private final String kind;
    private final String description;
    private final String apiVersion;
    
    KubernetesResourceType(String kind, String description, String apiVersion) {
        this.kind = kind;
        this.description = description;
        this.apiVersion = apiVersion;
    }
    
    // getters...
}
```

### Kubernetes资源状态枚举

```java
/**
 * Kubernetes资源状态枚举
 */
public enum KubernetesResourceStatus {
    /**
     * 创建中
     */
    CREATING("CREATING", "创建中"),
    
    /**
     * 运行中
     */
    RUNNING("RUNNING", "运行中"),
    
    /**
     * 更新中
     */
    UPDATING("UPDATING", "更新中"),
    
    /**
     * 删除中
     */
    DELETING("DELETING", "删除中"),
    
    /**
     * 失败
     */
    FAILED("FAILED", "失败"),
    
    /**
     * 已删除
     */
    DELETED("DELETED", "已删除");
    
    private final String code;
    private final String description;
    
    KubernetesResourceStatus(String code, String description) {
        this.code = code;
        this.description = description;
    }
    
    // getters...
}
```

## Kubernetes管理服务

### Kubernetes资源管理服务

```java
/**
 * Kubernetes资源管理服务
 * 负责K8s资源的创建、更新、删除和监控
 */
@Service
@Slf4j
public class KubernetesResourceService {
    
    @Autowired
    private KubernetesResourceRepository kubernetesResourceRepository;
    
    @Autowired
    private KubernetesClient kubernetesClient;
    
    @Autowired
    private YamlTemplateService yamlTemplateService;
    
    /**
     * 创建Kubernetes资源
     * 
     * @param resourceName 资源名称
     * @param resourceType 资源类型
     * @param namespace 命名空间
     * @param clusterName 集群名称
     * @param templateParams 模板参数
     * @return Kubernetes资源
     */
    @Transactional
    public KubernetesResource createResource(String resourceName,
                                           KubernetesResourceType resourceType,
                                           String namespace,
                                           String clusterName,
                                           Map<String, Object> templateParams) {
        log.info("创建Kubernetes资源: name={}, type={}, namespace={}, cluster={}", 
                resourceName, resourceType, namespace, clusterName);
        
        try {
            // 1. 生成资源配置
            String resourceConfig = generateResourceConfig(resourceType, templateParams);
            
            // 2. 创建资源记录
            KubernetesResource resource = new KubernetesResource();
            resource.setResourceName(resourceName);
            resource.setResourceType(resourceType);
            resource.setNamespace(namespace);
            resource.setClusterName(clusterName);
            resource.setResourceConfig(resourceConfig);
            resource.setResourceStatus(KubernetesResourceStatus.CREATING);
            resource.setLabels(JsonUtils.toJson(templateParams.get("labels")));
            resource.setAnnotations(JsonUtils.toJson(templateParams.get("annotations")));
            resource.setCreatedAt(LocalDateTime.now());
            
            resource = kubernetesResourceRepository.save(resource);
            
            // 3. 应用到Kubernetes集群
            applyResourceToCluster(resource);
            
            // 4. 更新状态
            resource.setResourceStatus(KubernetesResourceStatus.RUNNING);
            resource.setUpdatedAt(LocalDateTime.now());
            
            log.info("Kubernetes资源创建成功: id={}, name={}", resource.getId(), resourceName);
            return kubernetesResourceRepository.save(resource);
            
        } catch (Exception e) {
            log.error("创建Kubernetes资源失败", e);
            throw new RuntimeException("创建Kubernetes资源失败: " + e.getMessage());
        }
    }
    
    /**
     * 生成资源配置
     */
    private String generateResourceConfig(KubernetesResourceType resourceType, 
                                        Map<String, Object> templateParams) {
        switch (resourceType) {
            case DEPLOYMENT:
                return generateDeploymentConfig(templateParams);
            case SERVICE:
                return generateServiceConfig(templateParams);
            case CONFIG_MAP:
                return generateConfigMapConfig(templateParams);
            case SECRET:
                return generateSecretConfig(templateParams);
            case INGRESS:
                return generateIngressConfig(templateParams);
            case HORIZONTAL_POD_AUTOSCALER:
                return generateHPAConfig(templateParams);
            default:
                throw new RuntimeException("不支持的资源类型: " + resourceType);
        }
    }
    
    /**
     * 生成Deployment配置
     */
    private String generateDeploymentConfig(Map<String, Object> params) {
        String template = """
                apiVersion: apps/v1
                kind: Deployment
                metadata:
                  name: ${name}
                  namespace: ${namespace}
                  labels:
                    app: ${appName}
                    version: ${version}
                spec:
                  replicas: ${replicas}
                  selector:
                    matchLabels:
                      app: ${appName}
                  strategy:
                    type: ${strategyType}
                    rollingUpdate:
                      maxSurge: ${maxSurge}
                      maxUnavailable: ${maxUnavailable}
                  template:
                    metadata:
                      labels:
                        app: ${appName}
                        version: ${version}
                    spec:
                      containers:
                      - name: ${containerName}
                        image: ${image}
                        ports:
                        - containerPort: ${containerPort}
                        env:
                        - name: SPRING_PROFILES_ACTIVE
                          value: "${profile}"
                        - name: MYSQL_URL
                          valueFrom:
                            secretKeyRef:
                              name: mysql-secret
                              key: url
                        - name: MYSQL_USERNAME
                          valueFrom:
                            secretKeyRef:
                              name: mysql-secret
                              key: username
                        - name: MYSQL_PASSWORD
                          valueFrom:
                            secretKeyRef:
                              name: mysql-secret
                              key: password
                        - name: REDIS_HOST
                          valueFrom:
                            configMapKeyRef:
                              name: redis-config
                              key: host
                        - name: REDIS_PORT
                          valueFrom:
                            configMapKeyRef:
                              name: redis-config
                              key: port
                        resources:
                          requests:
                            memory: "${requestMemory}"
                            cpu: "${requestCpu}"
                          limits:
                            memory: "${limitMemory}"
                            cpu: "${limitCpu}"
                        livenessProbe:
                          httpGet:
                            path: /actuator/health
                            port: ${containerPort}
                          initialDelaySeconds: 60
                          periodSeconds: 30
                          timeoutSeconds: 10
                          failureThreshold: 3
                        readinessProbe:
                          httpGet:
                            path: /actuator/health
                            port: ${containerPort}
                          initialDelaySeconds: 30
                          periodSeconds: 10
                          timeoutSeconds: 5
                          failureThreshold: 3
                        volumeMounts:
                        - name: config-volume
                          mountPath: /app/config
                        - name: log-volume
                          mountPath: /app/logs
                      volumes:
                      - name: config-volume
                        configMap:
                          name: ${appName}-config
                      - name: log-volume
                        emptyDir: {}
                      serviceAccountName: ${serviceAccount}
                      securityContext:
                        runAsNonRoot: true
                        runAsUser: 1000
                        fsGroup: 1000
                """;
        
        return yamlTemplateService.processTemplate(template, params);
    }
    
    /**
     * 生成Service配置
     */
    private String generateServiceConfig(Map<String, Object> params) {
        String template = """
                apiVersion: v1
                kind: Service
                metadata:
                  name: ${name}
                  namespace: ${namespace}
                  labels:
                    app: ${appName}
                spec:
                  selector:
                    app: ${appName}
                  ports:
                  - name: http
                    protocol: TCP
                    port: ${servicePort}
                    targetPort: ${targetPort}
                  type: ${serviceType}
                """;
        
        return yamlTemplateService.processTemplate(template, params);
    }
    
    /**
     * 生成ConfigMap配置
     */
    private String generateConfigMapConfig(Map<String, Object> params) {
        String template = """
                apiVersion: v1
                kind: ConfigMap
                metadata:
                  name: ${name}
                  namespace: ${namespace}
                  labels:
                    app: ${appName}
                data:
                  application.yml: |
                    server:
                      port: 8080
                    spring:
                      application:
                        name: ${appName}
                      profiles:
                        active: ${profile}
                      datasource:
                        driver-class-name: com.mysql.cj.jdbc.Driver
                        hikari:
                          maximum-pool-size: 20
                          minimum-idle: 5
                          connection-timeout: 30000
                          idle-timeout: 600000
                          max-lifetime: 1800000
                      jpa:
                        hibernate:
                          ddl-auto: validate
                        show-sql: false
                        properties:
                          hibernate:
                            dialect: org.hibernate.dialect.MySQL8Dialect
                            format_sql: true
                      redis:
                        timeout: 5000
                        lettuce:
                          pool:
                            max-active: 20
                            max-idle: 10
                            min-idle: 5
                    logging:
                      level:
                        com.nsrs: ${logLevel}
                      pattern:
                        console: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"
                        file: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"
                      file:
                        name: /app/logs/application.log
                    management:
                      endpoints:
                        web:
                          exposure:
                            include: health,info,metrics,prometheus
                      endpoint:
                        health:
                          show-details: always
                """;
        
        return yamlTemplateService.processTemplate(template, params);
    }
    
    /**
     * 生成Secret配置
     */
    private String generateSecretConfig(Map<String, Object> params) {
        String template = """
                apiVersion: v1
                kind: Secret
                metadata:
                  name: ${name}
                  namespace: ${namespace}
                  labels:
                    app: ${appName}
                type: Opaque
                data:
                  url: ${mysqlUrlBase64}
                  username: ${mysqlUsernameBase64}
                  password: ${mysqlPasswordBase64}
                """;
        
        return yamlTemplateService.processTemplate(template, params);
    }
    
    /**
     * 生成Ingress配置
     */
    private String generateIngressConfig(Map<String, Object> params) {
        String template = """
                apiVersion: networking.k8s.io/v1
                kind: Ingress
                metadata:
                  name: ${name}
                  namespace: ${namespace}
                  labels:
                    app: ${appName}
                  annotations:
                    nginx.ingress.kubernetes.io/rewrite-target: /
                    nginx.ingress.kubernetes.io/ssl-redirect: "true"
                    nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
                    cert-manager.io/cluster-issuer: "letsencrypt-prod"
                spec:
                  tls:
                  - hosts:
                    - ${hostname}
                    secretName: ${tlsSecretName}
                  rules:
                  - host: ${hostname}
                    http:
                      paths:
                      - path: /
                        pathType: Prefix
                        backend:
                          service:
                            name: ${serviceName}
                            port:
                              number: ${servicePort}
                """;
        
        return yamlTemplateService.processTemplate(template, params);
    }
    
    /**
     * 生成HPA配置
     */
    private String generateHPAConfig(Map<String, Object> params) {
        String template = """
                apiVersion: autoscaling/v2
                kind: HorizontalPodAutoscaler
                metadata:
                  name: ${name}
                  namespace: ${namespace}
                  labels:
                    app: ${appName}
                spec:
                  scaleTargetRef:
                    apiVersion: apps/v1
                    kind: Deployment
                    name: ${deploymentName}
                  minReplicas: ${minReplicas}
                  maxReplicas: ${maxReplicas}
                  metrics:
                  - type: Resource
                    resource:
                      name: cpu
                      target:
                        type: Utilization
                        averageUtilization: ${cpuTargetUtilization}
                  - type: Resource
                    resource:
                      name: memory
                      target:
                        type: Utilization
                        averageUtilization: ${memoryTargetUtilization}
                  behavior:
                    scaleUp:
                      stabilizationWindowSeconds: 60
                      policies:
                      - type: Percent
                        value: 50
                        periodSeconds: 60
                    scaleDown:
                      stabilizationWindowSeconds: 300
                      policies:
                      - type: Percent
                        value: 10
                        periodSeconds: 60
                """;
        
        return yamlTemplateService.processTemplate(template, params);
    }
    
    /**
     * 应用资源到集群
     */
    private void applyResourceToCluster(KubernetesResource resource) {
        try {
            // 使用Kubernetes Java客户端应用资源
            switch (resource.getResourceType()) {
                case DEPLOYMENT:
                    applyDeployment(resource);
                    break;
                case SERVICE:
                    applyService(resource);
                    break;
                case CONFIG_MAP:
                    applyConfigMap(resource);
                    break;
                case SECRET:
                    applySecret(resource);
                    break;
                case INGRESS:
                    applyIngress(resource);
                    break;
                case HORIZONTAL_POD_AUTOSCALER:
                    applyHPA(resource);
                    break;
                default:
                    throw new RuntimeException("不支持的资源类型: " + resource.getResourceType());
            }
        } catch (Exception e) {
            log.error("应用资源到集群失败", e);
            throw new RuntimeException("应用资源到集群失败: " + e.getMessage());
        }
    }
    
    /**
     * 应用Deployment
     */
    private void applyDeployment(KubernetesResource resource) {
        // 解析YAML配置
        Yaml yaml = new Yaml();
        Map<String, Object> deploymentMap = yaml.load(resource.getResourceConfig());
        
        // 转换为Deployment对象
        V1Deployment deployment = kubernetesClient.getAppsV1Api()
                .createNamespacedDeployment(
                        resource.getNamespace(),
                        convertToDeployment(deploymentMap),
                        null, null, null, null
                );
        
        log.info("Deployment应用成功: {}", deployment.getMetadata().getName());
    }
    
    /**
     * 应用Service
     */
    private void applyService(KubernetesResource resource) {
        Yaml yaml = new Yaml();
        Map<String, Object> serviceMap = yaml.load(resource.getResourceConfig());
        
        V1Service service = kubernetesClient.getCoreV1Api()
                .createNamespacedService(
                        resource.getNamespace(),
                        convertToService(serviceMap),
                        null, null, null, null
                );
        
        log.info("Service应用成功: {}", service.getMetadata().getName());
    }
    
    /**
     * 应用ConfigMap
     */
    private void applyConfigMap(KubernetesResource resource) {
        Yaml yaml = new Yaml();
        Map<String, Object> configMapMap = yaml.load(resource.getResourceConfig());
        
        V1ConfigMap configMap = kubernetesClient.getCoreV1Api()
                .createNamespacedConfigMap(
                        resource.getNamespace(),
                        convertToConfigMap(configMapMap),
                        null, null, null, null
                );
        
        log.info("ConfigMap应用成功: {}", configMap.getMetadata().getName());
    }
    
    /**
     * 应用Secret
     */
    private void applySecret(KubernetesResource resource) {
        Yaml yaml = new Yaml();
        Map<String, Object> secretMap = yaml.load(resource.getResourceConfig());
        
        V1Secret secret = kubernetesClient.getCoreV1Api()
                .createNamespacedSecret(
                        resource.getNamespace(),
                        convertToSecret(secretMap),
                        null, null, null, null
                );
        
        log.info("Secret应用成功: {}", secret.getMetadata().getName());
    }
    
    /**
     * 应用Ingress
     */
    private void applyIngress(KubernetesResource resource) {
        Yaml yaml = new Yaml();
        Map<String, Object> ingressMap = yaml.load(resource.getResourceConfig());
        
        V1Ingress ingress = kubernetesClient.getNetworkingV1Api()
                .createNamespacedIngress(
                        resource.getNamespace(),
                        convertToIngress(ingressMap),
                        null, null, null, null
                );
        
        log.info("Ingress应用成功: {}", ingress.getMetadata().getName());
    }
    
    /**
     * 应用HPA
     */
    private void applyHPA(KubernetesResource resource) {
        Yaml yaml = new Yaml();
        Map<String, Object> hpaMap = yaml.load(resource.getResourceConfig());
        
        V2HorizontalPodAutoscaler hpa = kubernetesClient.getAutoscalingV2Api()
                .createNamespacedHorizontalPodAutoscaler(
                        resource.getNamespace(),
                        convertToHPA(hpaMap),
                        null, null, null, null
                );
        
        log.info("HPA应用成功: {}", hpa.getMetadata().getName());
    }
    
    /**
     * 更新Kubernetes资源
     */
    @Transactional
    public KubernetesResource updateResource(Long resourceId, Map<String, Object> updateParams) {
        log.info("更新Kubernetes资源: resourceId={}", resourceId);
        
        KubernetesResource resource = kubernetesResourceRepository.findById(resourceId)
                .orElseThrow(() -> new RuntimeException("Kubernetes资源不存在: " + resourceId));
        
        try {
            // 更新资源状态
            resource.setResourceStatus(KubernetesResourceStatus.UPDATING);
            kubernetesResourceRepository.save(resource);
            
            // 重新生成配置
            String newConfig = generateResourceConfig(resource.getResourceType(), updateParams);
            resource.setResourceConfig(newConfig);
            
            // 应用更新到集群
            updateResourceInCluster(resource);
            
            // 更新状态
            resource.setResourceStatus(KubernetesResourceStatus.RUNNING);
            resource.setUpdatedAt(LocalDateTime.now());
            
            log.info("Kubernetes资源更新成功: id={}", resourceId);
            return kubernetesResourceRepository.save(resource);
            
        } catch (Exception e) {
            log.error("更新Kubernetes资源失败", e);
            resource.setResourceStatus(KubernetesResourceStatus.FAILED);
            kubernetesResourceRepository.save(resource);
            throw new RuntimeException("更新Kubernetes资源失败: " + e.getMessage());
        }
    }
    
    /**
     * 删除Kubernetes资源
     */
    @Transactional
    public void deleteResource(Long resourceId) {
        log.info("删除Kubernetes资源: resourceId={}", resourceId);
        
        KubernetesResource resource = kubernetesResourceRepository.findById(resourceId)
                .orElseThrow(() -> new RuntimeException("Kubernetes资源不存在: " + resourceId));
        
        try {
            // 更新资源状态
            resource.setResourceStatus(KubernetesResourceStatus.DELETING);
            kubernetesResourceRepository.save(resource);
            
            // 从集群删除资源
            deleteResourceFromCluster(resource);
            
            // 更新状态
            resource.setResourceStatus(KubernetesResourceStatus.DELETED);
            resource.setUpdatedAt(LocalDateTime.now());
            kubernetesResourceRepository.save(resource);
            
            log.info("Kubernetes资源删除成功: id={}", resourceId);
            
        } catch (Exception e) {
            log.error("删除Kubernetes资源失败", e);
            resource.setResourceStatus(KubernetesResourceStatus.FAILED);
            kubernetesResourceRepository.save(resource);
            throw new RuntimeException("删除Kubernetes资源失败: " + e.getMessage());
        }
    }
    
    /**
     * 获取资源状态
     */
    public Map<String, Object> getResourceStatus(Long resourceId) {
        KubernetesResource resource = kubernetesResourceRepository.findById(resourceId)
                .orElseThrow(() -> new RuntimeException("Kubernetes资源不存在: " + resourceId));
        
        Map<String, Object> status = new HashMap<>();
        status.put("resourceId", resource.getId());
        status.put("resourceName", resource.getResourceName());
        status.put("resourceType", resource.getResourceType());
        status.put("namespace", resource.getNamespace());
        status.put("clusterName", resource.getClusterName());
        status.put("status", resource.getResourceStatus());
        status.put("createdAt", resource.getCreatedAt());
        status.put("updatedAt", resource.getUpdatedAt());
        
        // 从集群获取实时状态
        try {
            Map<String, Object> clusterStatus = getResourceStatusFromCluster(resource);
            status.putAll(clusterStatus);
        } catch (Exception e) {
            log.warn("获取集群资源状态失败: {}", resource.getResourceName(), e);
            status.put("clusterStatus", "UNKNOWN");
        }
        
        return status;
    }
    
    // 辅助方法实现...
    private void updateResourceInCluster(KubernetesResource resource) { /* 实现集群资源更新逻辑 */ }
    private void deleteResourceFromCluster(KubernetesResource resource) { /* 实现集群资源删除逻辑 */ }
    private Map<String, Object> getResourceStatusFromCluster(KubernetesResource resource) { /* 实现集群状态获取逻辑 */ return new HashMap<>(); }
    private V1Deployment convertToDeployment(Map<String, Object> deploymentMap) { /* 实现YAML到Deployment转换 */ return new V1Deployment(); }
    private V1Service convertToService(Map<String, Object> serviceMap) { /* 实现YAML到Service转换 */ return new V1Service(); }
    private V1ConfigMap convertToConfigMap(Map<String, Object> configMapMap) { /* 实现YAML到ConfigMap转换 */ return new V1ConfigMap(); }
    private V1Secret convertToSecret(Map<String, Object> secretMap) { /* 实现YAML到Secret转换 */ return new V1Secret(); }
    private V1Ingress convertToIngress(Map<String, Object> ingressMap) { /* 实现YAML到Ingress转换 */ return new V1Ingress(); }
    private V2HorizontalPodAutoscaler convertToHPA(Map<String, Object> hpaMap) { /* 实现YAML到HPA转换 */ return new V2HorizontalPodAutoscaler(); }
}
```

## Service Mesh管理服务

### Istio服务网格管理服务

```java
/**
 * Istio服务网格管理服务
 * 负责Service Mesh的配置和管理
 */
@Service
@Slf4j
public class IstioServiceMeshService {
    
    @Autowired
    private KubernetesClient kubernetesClient;
    
    @Autowired
    private YamlTemplateService yamlTemplateService;
    
    /**
     * 启用服务网格
     * 
     * @param namespace 命名空间
     * @param serviceName 服务名称
     * @return 是否成功
     */
    public boolean enableServiceMesh(String namespace, String serviceName) {
        log.info("为服务启用服务网格: namespace={}, service={}", namespace, serviceName);
        
        try {
            // 1. 创建VirtualService
            createVirtualService(namespace, serviceName);
            
            // 2. 创建DestinationRule
            createDestinationRule(namespace, serviceName);
            
            // 3. 创建ServiceEntry（如果需要）
            createServiceEntry(namespace, serviceName);
            
            // 4. 配置流量策略
            configureTrafficPolicy(namespace, serviceName);
            
            log.info("服务网格启用成功: namespace={}, service={}", namespace, serviceName);
            return true;
            
        } catch (Exception e) {
            log.error("启用服务网格失败", e);
            return false;
        }
    }
    
    /**
     * 创建VirtualService
     */
    private void createVirtualService(String namespace, String serviceName) {
        Map<String, Object> params = new HashMap<>();
        params.put("namespace", namespace);
        params.put("serviceName", serviceName);
        params.put("host", serviceName + "." + namespace + ".svc.cluster.local");
        
        String virtualServiceConfig = generateVirtualServiceConfig(params);
        
        // 应用VirtualService到集群
        applyIstioResource(virtualServiceConfig);
        
        log.info("VirtualService创建成功: {}", serviceName);
    }
    
    /**
     * 生成VirtualService配置
     */
    private String generateVirtualServiceConfig(Map<String, Object> params) {
        String template = """
                apiVersion: networking.istio.io/v1beta1
                kind: VirtualService
                metadata:
                  name: ${serviceName}-vs
                  namespace: ${namespace}
                spec:
                  hosts:
                  - ${host}
                  http:
                  - match:
                    - headers:
                        version:
                          exact: v1
                    route:
                    - destination:
                        host: ${host}
                        subset: v1
                      weight: 100
                  - match:
                    - headers:
                        version:
                          exact: v2
                    route:
                    - destination:
                        host: ${host}
                        subset: v2
                      weight: 100
                  - route:
                    - destination:
                        host: ${host}
                        subset: v1
                      weight: 90
                    - destination:
                        host: ${host}
                        subset: v2
                      weight: 10
                    timeout: 30s
                    retries:
                      attempts: 3
                      perTryTimeout: 10s
                """;
        
        return yamlTemplateService.processTemplate(template, params);
    }
    
    /**
     * 创建DestinationRule
     */
    private void createDestinationRule(String namespace, String serviceName) {
        Map<String, Object> params = new HashMap<>();
        params.put("namespace", namespace);
        params.put("serviceName", serviceName);
        params.put("host", serviceName + "." + namespace + ".svc.cluster.local");
        
        String destinationRuleConfig = generateDestinationRuleConfig(params);
        
        // 应用DestinationRule到集群
        applyIstioResource(destinationRuleConfig);
        
        log.info("DestinationRule创建成功: {}", serviceName);
    }
    
    /**
     * 生成DestinationRule配置
     */
    private String generateDestinationRuleConfig(Map<String, Object> params) {
        String template = """
                apiVersion: networking.istio.io/v1beta1
                kind: DestinationRule
                metadata:
                  name: ${serviceName}-dr
                  namespace: ${namespace}
                spec:
                  host: ${host}
                  trafficPolicy:
                    connectionPool:
                      tcp:
                        maxConnections: 100
                      http:
                        http1MaxPendingRequests: 50
                        http2MaxRequests: 100
                        maxRequestsPerConnection: 10
                        maxRetries: 3
                        consecutiveGatewayErrors: 5
                        interval: 30s
                        baseEjectionTime: 30s
                        maxEjectionPercent: 50
                    loadBalancer:
                      simple: LEAST_CONN
                    outlierDetection:
                      consecutiveGatewayErrors: 5
                      interval: 30s
                      baseEjectionTime: 30s
                      maxEjectionPercent: 50
                  subsets:
                  - name: v1
                    labels:
                      version: v1
                    trafficPolicy:
                      connectionPool:
                        tcp:
                          maxConnections: 50
                  - name: v2
                    labels:
                      version: v2
                    trafficPolicy:
                      connectionPool:
                        tcp:
                          maxConnections: 50
                """;
        
        return yamlTemplateService.processTemplate(template, params);
    }
    
    /**
     * 创建ServiceEntry
     */
    private void createServiceEntry(String namespace, String serviceName) {
        // 为外部服务创建ServiceEntry
        Map<String, Object> params = new HashMap<>();
        params.put("namespace", namespace);
        params.put("serviceName", serviceName);
        
        String serviceEntryConfig = generateServiceEntryConfig(params);
        
        // 应用ServiceEntry到集群
        applyIstioResource(serviceEntryConfig);
        
        log.info("ServiceEntry创建成功: {}", serviceName);
    }
    
    /**
     * 生成ServiceEntry配置
     */
    private String generateServiceEntryConfig(Map<String, Object> params) {
        String template = """
                apiVersion: networking.istio.io/v1beta1
                kind: ServiceEntry
                metadata:
                  name: external-mysql
                  namespace: ${namespace}
                spec:
                  hosts:
                  - mysql.external.com
                  ports:
                  - number: 3306
                    name: mysql
                    protocol: TCP
                  location: MESH_EXTERNAL
                  resolution: DNS
                """;
        
        return yamlTemplateService.processTemplate(template, params);
    }
    
    /**
     * 配置流量策略
     */
    private void configureTrafficPolicy(String namespace, String serviceName) {
        // 配置熔断器
        configureCircuitBreaker(namespace, serviceName);
        
        // 配置重试策略
        configureRetryPolicy(namespace, serviceName);
        
        // 配置超时策略
        configureTimeoutPolicy(namespace, serviceName);
        
        // 配置限流策略
        configureRateLimitPolicy(namespace, serviceName);
    }
    
    /**
     * 配置熔断器
     */
    private void configureCircuitBreaker(String namespace, String serviceName) {
        Map<String, Object> params = new HashMap<>();
        params.put("namespace", namespace);
        params.put("serviceName", serviceName);
        
        String circuitBreakerConfig = generateCircuitBreakerConfig(params);
        
        applyIstioResource(circuitBreakerConfig);
        
        log.info("熔断器配置成功: {}", serviceName);
    }
    
    /**
     * 生成熔断器配置
     */
    private String generateCircuitBreakerConfig(Map<String, Object> params) {
        String template = """
                apiVersion: networking.istio.io/v1beta1
                kind: DestinationRule
                metadata:
                  name: ${serviceName}-circuit-breaker
                  namespace: ${namespace}
                spec:
                  host: ${serviceName}
                  trafficPolicy:
                    outlierDetection:
                      consecutiveGatewayErrors: 5
                      consecutive5xxErrors: 5
                      interval: 30s
                      baseEjectionTime: 30s
                      maxEjectionPercent: 50
                      minHealthPercent: 50
                    connectionPool:
                      tcp:
                        maxConnections: 100
                        connectTimeout: 30s
                        tcpKeepalive:
                          time: 7200s
                          interval: 75s
                      http:
                        http1MaxPendingRequests: 50
                        http2MaxRequests: 100
                        maxRequestsPerConnection: 10
                        maxRetries: 3
                        idleTimeout: 90s
                        h2UpgradePolicy: UPGRADE
                """;
        
        return yamlTemplateService.processTemplate(template, params);
    }
    
    /**
     * 配置重试策略
     */
    private void configureRetryPolicy(String namespace, String serviceName) {
        // 重试策略已在VirtualService中配置
        log.info("重试策略配置成功: {}", serviceName);
    }
    
    /**
     * 配置超时策略
     */
    private void configureTimeoutPolicy(String namespace, String serviceName) {
        // 超时策略已在VirtualService中配置
        log.info("超时策略配置成功: {}", serviceName);
    }
    
    /**
     * 配置限流策略
     */
    private void configureRateLimitPolicy(String namespace, String serviceName) {
        Map<String, Object> params = new HashMap<>();
        params.put("namespace", namespace);
        params.put("serviceName", serviceName);
        
        String rateLimitConfig = generateRateLimitConfig(params);
        
        applyIstioResource(rateLimitConfig);
        
        log.info("限流策略配置成功: {}", serviceName);
    }
    
    /**
     * 生成限流配置
     */
    private String generateRateLimitConfig(Map<String, Object> params) {
        String template = """
                apiVersion: networking.istio.io/v1beta1
                kind: EnvoyFilter
                metadata:
                  name: ${serviceName}-rate-limit
                  namespace: ${namespace}
                spec:
                  workloadSelector:
                    labels:
                      app: ${serviceName}
                  configPatches:
                  - applyTo: HTTP_FILTER
                    match:
                      context: SIDECAR_INBOUND
                      listener:
                        filterChain:
                          filter:
                            name: "envoy.filters.network.http_connection_manager"
                    patch:
                      operation: INSERT_BEFORE
                      value:
                        name: envoy.filters.http.local_ratelimit
                        typed_config:
                          "@type": type.googleapis.com/udpa.type.v1.TypedStruct
                          type_url: type.googleapis.com/envoy.extensions.filters.http.local_ratelimit.v3.LocalRateLimit
                          value:
                            stat_prefix: local_rate_limiter
                            token_bucket:
                              max_tokens: 100
                              tokens_per_fill: 100
                              fill_interval: 60s
                            filter_enabled:
                              runtime_key: local_rate_limit_enabled
                              default_value:
                                numerator: 100
                                denominator: HUNDRED
                            filter_enforced:
                              runtime_key: local_rate_limit_enforced
                              default_value:
                                numerator: 100
                                denominator: HUNDRED
                """;
        
        return yamlTemplateService.processTemplate(template, params);
    }
    
    /**
     * 应用Istio资源
     */
    private void applyIstioResource(String resourceConfig) {
        try {
            // 使用kubectl apply应用资源
            ProcessBuilder processBuilder = new ProcessBuilder(
                    "kubectl", "apply", "-f", "-"
            );
            
            Process process = processBuilder.start();
            
            // 写入配置
            try (OutputStreamWriter writer = new OutputStreamWriter(process.getOutputStream())) {
                writer.write(resourceConfig);
                writer.flush();
            }
            
            int exitCode = process.waitFor();
            if (exitCode != 0) {
                throw new RuntimeException("应用Istio资源失败");
            }
            
        } catch (Exception e) {
            log.error("应用Istio资源失败", e);
            throw new RuntimeException("应用Istio资源失败: " + e.getMessage());
        }
    }
    
    /**
     * 获取服务网格状态
     */
    public Map<String, Object> getServiceMeshStatus(String namespace, String serviceName) {
        Map<String, Object> status = new HashMap<>();
        
        try {
            // 检查VirtualService状态
            boolean vsExists = checkVirtualServiceExists(namespace, serviceName);
            status.put("virtualServiceExists", vsExists);
            
            // 检查DestinationRule状态
            boolean drExists = checkDestinationRuleExists(namespace, serviceName);
            status.put("destinationRuleExists", drExists);
            
            // 检查Sidecar注入状态
            boolean sidecarInjected = checkSidecarInjected(namespace, serviceName);
            status.put("sidecarInjected", sidecarInjected);
            
            // 获取流量指标
            Map<String, Object> trafficMetrics = getTrafficMetrics(namespace, serviceName);
            status.put("trafficMetrics", trafficMetrics);
            
            status.put("meshEnabled", vsExists && drExists && sidecarInjected);
            
        } catch (Exception e) {
            log.error("获取服务网格状态失败", e);
            status.put("error", e.getMessage());
        }
        
        return status;
    }
    
    // 辅助方法实现...
    private boolean checkVirtualServiceExists(String namespace, String serviceName) { /* 实现VirtualService检查逻辑 */ return true; }
    private boolean checkDestinationRuleExists(String namespace, String serviceName) { /* 实现DestinationRule检查逻辑 */ return true; }
    private boolean checkSidecarInjected(String namespace, String serviceName) { /* 实现Sidecar注入检查逻辑 */ return true; }
    private Map<String, Object> getTrafficMetrics(String namespace, String serviceName) { /* 实现流量指标获取逻辑 */ return new HashMap<>(); }
}
```

## Demo脚本示例

### Kubernetes部署Demo脚本

```bash
#!/bin/bash

# NSRS Kubernetes部署Demo脚本
# 演示完整的K8s资源部署和管理

echo "=== NSRS Kubernetes部署Demo ==="
echo "演示场景：完整的云原生应用部署和管理"
echo

# 设置变量
NAMESPACE="nsrs-demo"
APP_NAME="nsrs-sim-card-mgnt"
IMAGE_TAG="nsrs-sim-card-mgnt:latest"
REPLICAS=3

# 1. 创建命名空间
echo "1. 创建命名空间..."
kubectl create namespace $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -

# 启用Istio注入
kubectl label namespace $NAMESPACE istio-injection=enabled --overwrite

echo "命名空间创建成功: $NAMESPACE"

# 2. 创建ConfigMap
echo "\n2. 创建ConfigMap..."
cat << EOF | kubectl apply -f -
apiVersion: v1
kind: ConfigMap
metadata:
  name: ${APP_NAME}-config
  namespace: $NAMESPACE
  labels:
    app: $APP_NAME
data:
  application.yml: |
    server:
      port: 8080
    spring:
      application:
        name: $APP_NAME
      profiles:
        active: prod
      datasource:
        driver-class-name: com.mysql.cj.jdbc.Driver
        hikari:
          maximum-pool-size: 20
          minimum-idle: 5
          connection-timeout: 30000
          idle-timeout: 600000
          max-lifetime: 1800000
      jpa:
        hibernate:
          ddl-auto: validate
        show-sql: false
        properties:
          hibernate:
            dialect: org.hibernate.dialect.MySQL8Dialect
            format_sql: true
      redis:
        timeout: 5000
        lettuce:
          pool:
            max-active: 20
            max-idle: 10
            min-idle: 5
    logging:
      level:
        com.nsrs: INFO
      pattern:
        console: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"
        file: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"
      file:
        name: /app/logs/application.log
    management:
      endpoints:
        web:
          exposure:
            include: health,info,metrics,prometheus
      endpoint:
        health:
          show-details: always
EOF

echo "ConfigMap创建成功"

# 3. 创建Secret
echo "\n3. 创建Secret..."
cat << EOF | kubectl apply -f -
apiVersion: v1
kind: Secret
metadata:
  name: mysql-secret
  namespace: $NAMESPACE
  labels:
    app: $APP_NAME
type: Opaque
data:
  url: $(echo -n "jdbc:mysql://mysql.nsrs.svc.cluster.local:3306/nsrs" | base64)
  username: $(echo -n "nsrs" | base64)
  password: $(echo -n "nsrs123456" | base64)
EOF

echo "Secret创建成功"

# 4. 创建ServiceAccount
echo "\n4. 创建ServiceAccount..."
cat << EOF | kubectl apply -f -
apiVersion: v1
kind: ServiceAccount
metadata:
  name: ${APP_NAME}-sa
  namespace: $NAMESPACE
  labels:
    app: $APP_NAME
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: ${APP_NAME}-role
  namespace: $NAMESPACE
rules:
- apiGroups: [""]
  resources: ["pods", "services", "configmaps"]
  verbs: ["get", "list", "watch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: ${APP_NAME}-rolebinding
  namespace: $NAMESPACE
subjects:
- kind: ServiceAccount
  name: ${APP_NAME}-sa
  namespace: $NAMESPACE
roleRef:
  kind: Role
  name: ${APP_NAME}-role
  apiGroup: rbac.authorization.k8s.io
EOF

echo "ServiceAccount创建成功"

# 5. 创建Deployment
echo "\n5. 创建Deployment..."
cat << EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: $APP_NAME
  namespace: $NAMESPACE
  labels:
    app: $APP_NAME
    version: v1
spec:
  replicas: $REPLICAS
  selector:
    matchLabels:
      app: $APP_NAME
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  template:
    metadata:
      labels:
        app: $APP_NAME
        version: v1
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "8080"
        prometheus.io/path: "/actuator/prometheus"
    spec:
      serviceAccountName: ${APP_NAME}-sa
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        fsGroup: 1000
      containers:
      - name: $APP_NAME
        image: $IMAGE_TAG
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 8080
          name: http
          protocol: TCP
        env:
        - name: SPRING_PROFILES_ACTIVE
          value: "prod"
        - name: MYSQL_URL
          valueFrom:
            secretKeyRef:
              name: mysql-secret
              key: url
        - name: MYSQL_USERNAME
          valueFrom:
            secretKeyRef:
              name: mysql-secret
              key: username
        - name: MYSQL_PASSWORD
          valueFrom:
            secretKeyRef:
              name: mysql-secret
              key: password
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: POD_IP
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /actuator/health
            port: 8080
          initialDelaySeconds: 60
          periodSeconds: 30
          timeoutSeconds: 10
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /actuator/health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        volumeMounts:
        - name: config-volume
          mountPath: /app/config
        - name: log-volume
          mountPath: /app/logs
      volumes:
      - name: config-volume
        configMap:
          name: ${APP_NAME}-config
      - name: log-volume
        emptyDir: {}
      terminationGracePeriodSeconds: 30
EOF

echo "Deployment创建成功"

# 6. 创建Service
echo "\n6. 创建Service..."
cat << EOF | kubectl apply -f -
apiVersion: v1
kind: Service
metadata:
  name: $APP_NAME
  namespace: $NAMESPACE
  labels:
    app: $APP_NAME
spec:
  selector:
    app: $APP_NAME
  ports:
  - name: http
    protocol: TCP
    port: 80
    targetPort: 8080
  type: ClusterIP
EOF

echo "Service创建成功"

# 7. 创建HPA
echo "\n7. 创建HPA..."
cat << EOF | kubectl apply -f -
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: ${APP_NAME}-hpa
  namespace: $NAMESPACE
  labels:
    app: $APP_NAME
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: $APP_NAME
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 10
        periodSeconds: 60
EOF

echo "HPA创建成功"

# 8. 创建Ingress
echo "\n8. 创建Ingress..."
cat << EOF | kubectl apply -f -
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ${APP_NAME}-ingress
  namespace: $NAMESPACE
  labels:
    app: $APP_NAME
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
spec:
  tls:
  - hosts:
    - nsrs-demo.example.com
    secretName: nsrs-demo-tls
  rules:
  - host: nsrs-demo.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: $APP_NAME
            port:
              number: 80
EOF

echo "Ingress创建成功"

# 9. 等待部署完成
echo "\n9. 等待部署完成..."
kubectl wait --for=condition=available --timeout=300s deployment/$APP_NAME -n $NAMESPACE

# 10. 验证部署状态
echo "\n10. 验证部署状态..."
echo "Pods状态:"
kubectl get pods -n $NAMESPACE -l app=$APP_NAME

echo "\nService状态:"
kubectl get svc -n $NAMESPACE -l app=$APP_NAME

echo "\nHPA状态:"
kubectl get hpa -n $NAMESPACE

echo "\nIngress状态:"
kubectl get ingress -n $NAMESPACE

# 11. 测试应用健康检查
echo "\n11. 测试应用健康检查..."
POD_NAME=$(kubectl get pods -n $NAMESPACE -l app=$APP_NAME -o jsonpath='{.items[0].metadata.name}')
kubectl exec -n $NAMESPACE $POD_NAME -- curl -s http://localhost:8080/actuator/health

echo "\n=== Kubernetes部署Demo完成 ==="
echo "应用已成功部署到集群，可通过以下方式访问："
echo "- 集群内访问: http://$APP_NAME.$NAMESPACE.svc.cluster.local"
echo "- 外部访问: https://nsrs-demo.example.com"
echo "- 健康检查: https://nsrs-demo.example.com/actuator/health"
echo "- 监控指标: https://nsrs-demo.example.com/actuator/prometheus"
```

### Service Mesh部署Demo脚本

```bash
#!/bin/bash

# NSRS Service Mesh部署Demo脚本
# 演示Istio服务网格的配置和管理

echo "=== NSRS Service Mesh部署Demo ==="
echo "演示场景：Istio服务网格配置和流量管理"
echo

# 设置变量
NAMESPACE="nsrs-demo"
APP_NAME="nsrs-sim-card-mgnt"
VERSION_V1="v1"
VERSION_V2="v2"

# 1. 安装Istio（如果未安装）
echo "1. 检查Istio安装状态..."
if ! kubectl get namespace istio-system > /dev/null 2>&1; then
    echo "安装Istio..."
    curl -L https://istio.io/downloadIstio | sh -
    cd istio-*
    export PATH=$PWD/bin:$PATH
    istioctl install --set values.defaultRevision=default -y
    kubectl label namespace default istio-injection=enabled
else
    echo "Istio已安装"
fi

# 2. 启用命名空间的Istio注入
echo "\n2. 启用命名空间的Istio注入..."
kubectl label namespace $NAMESPACE istio-injection=enabled --overwrite
echo "Istio注入已启用: $NAMESPACE"

# 3. 重启Pod以注入Sidecar
echo "\n3. 重启Pod以注入Sidecar..."
kubectl rollout restart deployment/$APP_NAME -n $NAMESPACE
kubectl rollout status deployment/$APP_NAME -n $NAMESPACE

# 4. 创建VirtualService
echo "\n4. 创建VirtualService..."
cat << EOF | kubectl apply -f -
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: ${APP_NAME}-vs
  namespace: $NAMESPACE
spec:
  hosts:
  - ${APP_NAME}.${NAMESPACE}.svc.cluster.local
  - nsrs-demo.example.com
  gateways:
  - ${APP_NAME}-gateway
  - mesh
  http:
  - match:
    - headers:
        version:
          exact: v2
    route:
    - destination:
        host: ${APP_NAME}.${NAMESPACE}.svc.cluster.local
        subset: v2
      weight: 100
    timeout: 30s
    retries:
      attempts: 3
      perTryTimeout: 10s
  - match:
    - uri:
        prefix: "/api/v2"
    route:
    - destination:
        host: ${APP_NAME}.${NAMESPACE}.svc.cluster.local
        subset: v2
      weight: 100
  - route:
    - destination:
        host: ${APP_NAME}.${NAMESPACE}.svc.cluster.local
        subset: v1
      weight: 90
    - destination:
        host: ${APP_NAME}.${NAMESPACE}.svc.cluster.local
        subset: v2
      weight: 10
    timeout: 30s
    retries:
      attempts: 3
      perTryTimeout: 10s
    fault:
      delay:
        percentage:
          value: 0.1
        fixedDelay: 5s
EOF

echo "VirtualService创建成功"

# 5. 创建DestinationRule
echo "\n5. 创建DestinationRule..."
cat << EOF | kubectl apply -f -
apiVersion: networking.istio.io/v1beta1
kind: DestinationRule
metadata:
  name: ${APP_NAME}-dr
  namespace: $NAMESPACE
spec:
  host: ${APP_NAME}.${NAMESPACE}.svc.cluster.local
  trafficPolicy:
    connectionPool:
      tcp:
        maxConnections: 100
        connectTimeout: 30s
        tcpKeepalive:
          time: 7200s
          interval: 75s
      http:
        http1MaxPendingRequests: 50
        http2MaxRequests: 100
        maxRequestsPerConnection: 10
        maxRetries: 3
        idleTimeout: 90s
        h2UpgradePolicy: UPGRADE
    loadBalancer:
      simple: LEAST_CONN
    outlierDetection:
      consecutiveGatewayErrors: 5
      consecutive5xxErrors: 5
      interval: 30s
      baseEjectionTime: 30s
      maxEjectionPercent: 50
      minHealthPercent: 50
  subsets:
  - name: v1
    labels:
      version: v1
    trafficPolicy:
      connectionPool:
        tcp:
          maxConnections: 50
  - name: v2
    labels:
      version: v2
    trafficPolicy:
      connectionPool:
        tcp:
          maxConnections: 50
EOF

echo "DestinationRule创建成功"

# 6. 创建Gateway
echo "\n6. 创建Gateway..."
cat << EOF | kubectl apply -f -
apiVersion: networking.istio.io/v1beta1
kind: Gateway
metadata:
  name: ${APP_NAME}-gateway
  namespace: $NAMESPACE
spec:
  selector:
    istio: ingressgateway
  servers:
  - port:
      number: 80
      name: http
      protocol: HTTP
    hosts:
    - nsrs-demo.example.com
    tls:
      httpsRedirect: true
  - port:
      number: 443
      name: https
      protocol: HTTPS
    tls:
      mode: SIMPLE
      credentialName: nsrs-demo-tls
    hosts:
    - nsrs-demo.example.com
EOF

echo "Gateway创建成功"

# 7. 创建ServiceEntry（外部服务）
echo "\n7. 创建ServiceEntry..."
cat << EOF | kubectl apply -f -
apiVersion: networking.istio.io/v1beta1
kind: ServiceEntry
metadata:
  name: external-mysql
  namespace: $NAMESPACE
spec:
  hosts:
  - mysql.external.com
  ports:
  - number: 3306
    name: mysql
    protocol: TCP
  location: MESH_EXTERNAL
  resolution: DNS
---
apiVersion: networking.istio.io/v1beta1
kind: ServiceEntry
metadata:
  name: external-redis
  namespace: $NAMESPACE
spec:
  hosts:
  - redis.external.com
  ports:
  - number: 6379
    name: redis
    protocol: TCP
  location: MESH_EXTERNAL
  resolution: DNS
EOF

echo "ServiceEntry创建成功"

# 8. 配置限流策略
echo "\n8. 配置限流策略..."
cat << EOF | kubectl apply -f -
apiVersion: networking.istio.io/v1beta1
kind: EnvoyFilter
metadata:
  name: ${APP_NAME}-rate-limit
  namespace: $NAMESPACE
spec:
  workloadSelector:
    labels:
      app: $APP_NAME
  configPatches:
  - applyTo: HTTP_FILTER
    match:
      context: SIDECAR_INBOUND
      listener:
        filterChain:
          filter:
            name: "envoy.filters.network.http_connection_manager"
    patch:
      operation: INSERT_BEFORE
      value:
        name: envoy.filters.http.local_ratelimit
        typed_config:
          "@type": type.googleapis.com/udpa.type.v1.TypedStruct
          type_url: type.googleapis.com/envoy.extensions.filters.http.local_ratelimit.v3.LocalRateLimit
          value:
            stat_prefix: local_rate_limiter
            token_bucket:
              max_tokens: 1000
              tokens_per_fill: 1000
              fill_interval: 60s
            filter_enabled:
              runtime_key: local_rate_limit_enabled
              default_value:
                numerator: 100
                denominator: HUNDRED
            filter_enforced:
              runtime_key: local_rate_limit_enforced
              default_value:
                numerator: 100
                denominator: HUNDRED
EOF

echo "限流策略配置成功"

# 9. 配置安全策略
echo "\n9. 配置安全策略..."
cat << EOF | kubectl apply -f -
apiVersion: security.istio.io/v1beta1
kind: PeerAuthentication
metadata:
  name: ${APP_NAME}-peer-auth
  namespace: $NAMESPACE
spec:
  selector:
    matchLabels:
      app: $APP_NAME
  mtls:
    mode: STRICT
---
apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: ${APP_NAME}-authz
  namespace: $NAMESPACE
spec:
  selector:
    matchLabels:
      app: $APP_NAME
  rules:
  - from:
    - source:
        principals: ["cluster.local/ns/istio-system/sa/istio-ingressgateway-service-account"]
  - from:
    - source:
        namespaces: ["nsrs-demo"]
    to:
    - operation:
        methods: ["GET", "POST", "PUT", "DELETE"]
        paths: ["/api/*"]
EOF

echo "安全策略配置成功"

# 10. 验证Service Mesh状态
echo "\n10. 验证Service Mesh状态..."
echo "检查Sidecar注入状态:"
kubectl get pods -n $NAMESPACE -o jsonpath='{range .items[*]}{.metadata.name}{"\t"}{.spec.containers[*].name}{"\n"}{end}'

echo "\n检查VirtualService状态:"
kubectl get virtualservice -n $NAMESPACE

echo "\n检查DestinationRule状态:"
kubectl get destinationrule -n $NAMESPACE

echo "\n检查Gateway状态:"
kubectl get gateway -n $NAMESPACE

echo "\n检查ServiceEntry状态:"
kubectl get serviceentry -n $NAMESPACE

# 11. 测试流量路由
echo "\n11. 测试流量路由..."
echo "测试默认路由（90% v1, 10% v2）:"
for i in {1..10}; do
    kubectl exec -n $NAMESPACE deployment/$APP_NAME -- curl -s http://$APP_NAME/actuator/info | jq -r '.version // "v1"'
done

echo "\n测试版本路由（强制v2）:"
kubectl exec -n $NAMESPACE deployment/$APP_NAME -- curl -s -H "version: v2" http://$APP_NAME/actuator/info | jq -r '.version // "v2"'

# 12. 查看流量指标
echo "\n12. 查看流量指标..."
echo "获取Istio代理配置:"
kubectl exec -n $NAMESPACE deployment/$APP_NAME -c istio-proxy -- pilot-agent request GET stats/prometheus | grep istio

echo "\n=== Service Mesh部署Demo完成 ==="
echo "服务网格已成功配置，功能包括："
echo "- Sidecar自动注入"
echo "- 智能流量路由（90% v1, 10% v2）"
echo "- 熔断和重试机制"
echo "- 限流保护"
echo "- mTLS安全通信"
echo "- 访问控制策略"
echo "- 可观测性和监控"
```

## 最佳实践总结

### 容器化最佳实践

1. **镜像优化**
   - 使用多阶段构建减小镜像体积
   - 选择合适的基础镜像（Alpine Linux）
   - 定期更新基础镜像修复安全漏洞
   - 使用.dockerignore排除不必要文件

2. **安全配置**
   - 以非root用户运行容器
   - 设置资源限制防止资源耗尽
   - 使用只读文件系统
   - 定期扫描镜像安全漏洞

3. **配置管理**
   - 使用ConfigMap管理配置文件
   - 使用Secret管理敏感信息
   - 环境变量注入运行时配置
   - 配置热更新机制

### Kubernetes部署最佳实践

1. **资源管理**
   - 合理设置资源请求和限制
   - 使用HPA实现自动扩缩容
   - 配置Pod反亲和性提高可用性
   - 使用PodDisruptionBudget保证服务连续性

2. **健康检查**
   - 配置存活性探针检测应用健康
   - 配置就绪性探针控制流量路由
   - 设置合理的探针参数
   - 实现优雅关闭机制

3. **网络安全**
   - 使用NetworkPolicy限制网络访问
   - 配置RBAC控制API访问权限
   - 启用Pod安全策略
   - 使用ServiceAccount隔离权限

### Service Mesh最佳实践

1. **流量管理**
   - 实施金丝雀发布策略
   - 配置智能负载均衡
   - 设置合理的超时和重试策略
   - 实现故障注入测试

2. **安全策略**
   - 启用mTLS加密服务间通信
   - 配置细粒度访问控制策略
   - 实施零信任网络架构
   - 定期轮换证书

3. **可观测性**
   - 收集分布式链路追踪数据
   - 监控服务间通信指标
   - 配置告警规则
   - 实现日志聚合和分析

### 运维监控最佳实践

1. **监控体系**
   - 建立多层次监控体系
   - 配置关键指标告警
   - 实现自动化故障恢复
   - 定期进行容灾演练

2. **日志管理**
   - 统一日志格式和标准
   - 实现日志集中收集
   - 配置日志轮转和清理
   - 建立日志分析和检索能力

3. **性能优化**
   - 定期进行性能基准测试
   - 优化资源配置和调度
   - 实施缓存策略
   - 监控和优化网络性能