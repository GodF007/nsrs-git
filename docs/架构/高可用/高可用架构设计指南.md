# 高可用架构设计指南

## 概述

高可用架构是确保NSRS号卡资源管理系统在面对各种故障时仍能持续提供服务的关键。本文档详细阐述了基于NSRS系统的高可用架构设计方案，包括负载均衡、容灾备份、故障转移、监控告警等核心组件。

### 架构目标

- **可用性目标**: 99.99%（年停机时间不超过52.56分钟）
- **RTO（恢复时间目标）**: < 5分钟
- **RPO（恢复点目标）**: < 1分钟
- **故障检测时间**: < 30秒
- **自动故障转移时间**: < 2分钟

### 高可用架构图

```
┌─────────────────────────────────────────────────────────────────┐
│                        Internet/CDN                             │
└─────────────────────┬───────────────────────────────────────────┘
                      │
┌─────────────────────┴───────────────────────────────────────────┐
│                   WAF + DDoS Protection                         │
└─────────────────────┬───────────────────────────────────────────┘
                      │
┌─────────────────────┴───────────────────────────────────────────┐
│              Load Balancer (F5/Nginx/HAProxy)                   │
│                    Active-Active                                │
└─────────┬───────────────────────────────────┬───────────────────┘
          │                                   │
┌─────────┴─────────┐                ┌───────┴─────────┐
│   Data Center A   │                │   Data Center B │
│                   │                │                 │
│ ┌───────────────┐ │                │ ┌─────────────┐ │
│ │ Gateway Nodes │ │                │ │Gateway Nodes│ │
│ │   (Active)    │ │                │ │  (Standby)  │ │
│ └───────────────┘ │                │ └─────────────┘ │
│                   │                │                 │
│ ┌───────────────┐ │                │ ┌─────────────┐ │
│ │Service Cluster│ │                │ │Service      │ │
│ │   (Active)    │ │                │ │Cluster      │ │
│ └───────────────┘ │                │ │(Standby)    │ │
│                   │                │ └─────────────┘ │
│ ┌───────────────┐ │                │ ┌─────────────┐ │
│ │Database Master│ │◄──Replication──►│ │Database     │ │
│ │   (Active)    │ │                │ │Slave        │ │
│ └───────────────┘ │                │ │(Standby)    │ │
│                   │                │ └─────────────┘ │
└───────────────────┘                └─────────────────┘
```

## 负载均衡架构

### 1. 四层负载均衡（F5/LVS）

```yaml
# F5 BIG-IP配置示例
virtual_servers:
  - name: nsrs-web-vs
    destination: 10.1.1.100:80
    pool: nsrs-web-pool
    profiles:
      - http
      - tcp
    persistence: cookie
    
  - name: nsrs-api-vs
    destination: 10.1.1.101:8080
    pool: nsrs-api-pool
    profiles:
      - http
      - tcp
    persistence: source-ip

pools:
  - name: nsrs-web-pool
    load_balancing_method: round-robin
    health_monitor: http_monitor
    members:
      - address: 10.1.2.10
        port: 80
        priority: 100
      - address: 10.1.2.11
        port: 80
        priority: 100
      - address: 10.1.2.12
        port: 80
        priority: 90
        
  - name: nsrs-api-pool
    load_balancing_method: least-connections
    health_monitor: tcp_monitor
    members:
      - address: 10.1.3.10
        port: 8080
      - address: 10.1.3.11
        port: 8080
      - address: 10.1.3.12
        port: 8080

health_monitors:
  - name: http_monitor
    type: http
    interval: 5
    timeout: 3
    send_string: "GET /health HTTP/1.1\r\nHost: nsrs.example.com\r\n\r\n"
    receive_string: "200 OK"
    
  - name: tcp_monitor
    type: tcp
    interval: 3
    timeout: 2
```

### 2. 七层负载均衡（Nginx）

```nginx
# nginx.conf
upstream nsrs_backend {
    # 负载均衡策略
    least_conn;
    
    # 后端服务器
    server 10.1.3.10:8080 weight=3 max_fails=3 fail_timeout=30s;
    server 10.1.3.11:8080 weight=3 max_fails=3 fail_timeout=30s;
    server 10.1.3.12:8080 weight=2 max_fails=3 fail_timeout=30s backup;
    
    # 健康检查
    keepalive 32;
    keepalive_requests 100;
    keepalive_timeout 60s;
}

upstream nsrs_web {
    ip_hash;  # 会话保持
    
    server 10.1.2.10:80 weight=1;
    server 10.1.2.11:80 weight=1;
    server 10.1.2.12:80 weight=1 backup;
}

server {
    listen 80;
    server_name nsrs.example.com;
    
    # 重定向到HTTPS
    return 301 https://$server_name$request_uri;
}

server {
    listen 443 ssl http2;
    server_name nsrs.example.com;
    
    # SSL配置
    ssl_certificate /etc/nginx/ssl/nsrs.crt;
    ssl_certificate_key /etc/nginx/ssl/nsrs.key;
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES128-GCM-SHA256;
    ssl_prefer_server_ciphers on;
    ssl_session_cache shared:SSL:10m;
    ssl_session_timeout 10m;
    
    # 安全头
    add_header X-Frame-Options DENY;
    add_header X-Content-Type-Options nosniff;
    add_header X-XSS-Protection "1; mode=block";
    add_header Strict-Transport-Security "max-age=31536000; includeSubDomains";
    
    # 静态资源
    location /static/ {
        proxy_pass http://nsrs_web;
        proxy_cache static_cache;
        proxy_cache_valid 200 1h;
        expires 1h;
    }
    
    # API接口
    location /api/ {
        proxy_pass http://nsrs_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # 超时设置
        proxy_connect_timeout 5s;
        proxy_send_timeout 60s;
        proxy_read_timeout 60s;
        
        # 重试设置
        proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504;
        proxy_next_upstream_tries 3;
        proxy_next_upstream_timeout 10s;
    }
    
    # 健康检查
    location /health {
        access_log off;
        return 200 "healthy\n";
        add_header Content-Type text/plain;
    }
    
    # 限流配置
    location /api/imsi/allocate {
        limit_req zone=api_limit burst=10 nodelay;
        proxy_pass http://nsrs_backend;
    }
}

# 限流配置
http {
    limit_req_zone $binary_remote_addr zone=api_limit:10m rate=10r/s;
    limit_req_zone $binary_remote_addr zone=login_limit:10m rate=1r/s;
    
    # 缓存配置
    proxy_cache_path /var/cache/nginx/static levels=1:2 keys_zone=static_cache:10m max_size=1g inactive=1h;
}
```

### 3. HAProxy配置

```haproxy
# haproxy.cfg
global
    daemon
    user haproxy
    group haproxy
    pidfile /var/run/haproxy.pid
    
    # SSL配置
    ssl-default-bind-ciphers ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES128-GCM-SHA256
    ssl-default-bind-options ssl-min-ver TLSv1.2 no-tls-tickets
    
    # 统计信息
    stats socket /var/run/haproxy.sock mode 600 level admin
    stats timeout 2m

defaults
    mode http
    timeout connect 5000ms
    timeout client 50000ms
    timeout server 50000ms
    
    # 错误页面
    errorfile 400 /etc/haproxy/errors/400.http
    errorfile 403 /etc/haproxy/errors/403.http
    errorfile 408 /etc/haproxy/errors/408.http
    errorfile 500 /etc/haproxy/errors/500.http
    errorfile 502 /etc/haproxy/errors/502.http
    errorfile 503 /etc/haproxy/errors/503.http
    errorfile 504 /etc/haproxy/errors/504.http

# 前端配置
frontend nsrs_frontend
    bind *:80
    bind *:443 ssl crt /etc/haproxy/ssl/nsrs.pem
    
    # 重定向HTTP到HTTPS
    redirect scheme https if !{ ssl_fc }
    
    # ACL规则
    acl is_api path_beg /api/
    acl is_static path_beg /static/
    acl is_websocket hdr(Upgrade) -i websocket
    
    # 路由规则
    use_backend nsrs_api if is_api
    use_backend nsrs_static if is_static
    use_backend nsrs_websocket if is_websocket
    default_backend nsrs_web

# 后端配置
backend nsrs_api
    balance leastconn
    option httpchk GET /actuator/health
    http-check expect status 200
    
    server api1 10.1.3.10:8080 check inter 5s fall 3 rise 2 weight 100
    server api2 10.1.3.11:8080 check inter 5s fall 3 rise 2 weight 100
    server api3 10.1.3.12:8080 check inter 5s fall 3 rise 2 weight 50 backup

backend nsrs_web
    balance roundrobin
    cookie SERVERID insert indirect nocache
    option httpchk GET /health
    
    server web1 10.1.2.10:80 check cookie web1
    server web2 10.1.2.11:80 check cookie web2
    server web3 10.1.2.12:80 check cookie web3 backup

backend nsrs_static
    balance roundrobin
    option httpchk GET /health
    
    server static1 10.1.4.10:80 check
    server static2 10.1.4.11:80 check

backend nsrs_websocket
    balance source
    option httpchk GET /ws/health
    
    server ws1 10.1.5.10:8080 check
    server ws2 10.1.5.11:8080 check

# 统计页面
listen stats
    bind *:8404
    stats enable
    stats uri /stats
    stats refresh 30s
    stats admin if TRUE
```

## 容灾备份架构

### 1. 数据库主从复制

```sql
-- 主库配置 (my.cnf)
[mysqld]
server-id = 1
log-bin = mysql-bin
binlog-format = ROW
binlog-do-db = nsrs_db
gtid-mode = ON
enforce-gtid-consistency = ON

-- 从库配置 (my.cnf)
[mysqld]
server-id = 2
relay-log = relay-bin
read-only = 1
gtid-mode = ON
enforce-gtid-consistency = ON
log-slave-updates = 1

-- 创建复制用户
CREATE USER 'replication'@'%' IDENTIFIED BY 'repl_password';
GRANT REPLICATION SLAVE ON *.* TO 'replication'@'%';
FLUSH PRIVILEGES;

-- 配置主从复制
CHANGE MASTER TO
    MASTER_HOST='10.1.6.10',
    MASTER_USER='replication',
    MASTER_PASSWORD='repl_password',
    MASTER_AUTO_POSITION=1;

START SLAVE;
```

### 2. Redis哨兵模式

```yaml
# redis-master.conf
port 6379
bind 0.0.0.0
requireauth redis123
masterauth redis123
save 900 1
save 300 10
save 60 10000
appendonly yes
appendfsync everysec

# redis-slave.conf
port 6379
bind 0.0.0.0
requireauth redis123
masterauth redis123
slaveof 10.1.7.10 6379
slave-read-only yes
appendonly yes

# sentinel.conf
port 26379
bind 0.0.0.0
sentinel monitor nsrs-master 10.1.7.10 6379 2
sentinel auth-pass nsrs-master redis123
sentinel down-after-milliseconds nsrs-master 5000
sentinel parallel-syncs nsrs-master 1
sentinel failover-timeout nsrs-master 10000
sentinel deny-scripts-reconfig yes
```

```java
@Configuration
public class RedisConfig {
    
    @Bean
    public LettuceConnectionFactory redisConnectionFactory() {
        // 哨兵配置
        RedisSentinelConfiguration sentinelConfig = new RedisSentinelConfiguration()
            .master("nsrs-master")
            .sentinel("10.1.7.20", 26379)
            .sentinel("10.1.7.21", 26379)
            .sentinel("10.1.7.22", 26379);
        
        sentinelConfig.setPassword("redis123");
        
        // 连接池配置
        GenericObjectPoolConfig poolConfig = new GenericObjectPoolConfig();
        poolConfig.setMaxTotal(20);
        poolConfig.setMaxIdle(10);
        poolConfig.setMinIdle(5);
        poolConfig.setTestOnBorrow(true);
        poolConfig.setTestOnReturn(true);
        poolConfig.setTestWhileIdle(true);
        
        LettucePoolingClientConfiguration clientConfig = LettucePoolingClientConfiguration.builder()
            .poolConfig(poolConfig)
            .commandTimeout(Duration.ofSeconds(5))
            .shutdownTimeout(Duration.ofSeconds(10))
            .build();
        
        return new LettuceConnectionFactory(sentinelConfig, clientConfig);
    }
    
    @Bean
    public RedisTemplate<String, Object> redisTemplate(LettuceConnectionFactory connectionFactory) {
        RedisTemplate<String, Object> template = new RedisTemplate<>();
        template.setConnectionFactory(connectionFactory);
        
        // 序列化配置
        Jackson2JsonRedisSerializer<Object> serializer = new Jackson2JsonRedisSerializer<>(Object.class);
        ObjectMapper objectMapper = new ObjectMapper();
        objectMapper.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY);
        objectMapper.activateDefaultTyping(LaissezFaireSubTypeValidator.instance, ObjectMapper.DefaultTyping.NON_FINAL);
        serializer.setObjectMapper(objectMapper);
        
        template.setKeySerializer(new StringRedisSerializer());
        template.setHashKeySerializer(new StringRedisSerializer());
        template.setValueSerializer(serializer);
        template.setHashValueSerializer(serializer);
        
        template.afterPropertiesSet();
        return template;
    }
}
```

### 3. 文件存储备份

```bash
#!/bin/bash
# backup_files.sh - 文件备份脚本

SOURCE_DIR="/data/nsrs/files"
BACKUP_DIR="/backup/nsrs/files"
REMOTE_BACKUP="rsync://backup-server/nsrs-files"
LOG_FILE="/var/log/nsrs-backup.log"
RETENTION_DAYS=30

# 创建备份目录
mkdir -p $BACKUP_DIR

# 本地备份
echo "$(date): Starting local backup" >> $LOG_FILE
rsync -av --delete $SOURCE_DIR/ $BACKUP_DIR/
if [ $? -eq 0 ]; then
    echo "$(date): Local backup completed successfully" >> $LOG_FILE
else
    echo "$(date): Local backup failed" >> $LOG_FILE
    exit 1
fi

# 远程备份
echo "$(date): Starting remote backup" >> $LOG_FILE
rsync -av --delete $BACKUP_DIR/ $REMOTE_BACKUP/
if [ $? -eq 0 ]; then
    echo "$(date): Remote backup completed successfully" >> $LOG_FILE
else
    echo "$(date): Remote backup failed" >> $LOG_FILE
fi

# 清理过期备份
find $BACKUP_DIR -type f -mtime +$RETENTION_DAYS -delete
echo "$(date): Cleanup completed" >> $LOG_FILE
```

## 故障转移机制

### 1. 数据库故障转移

```java
@Component
public class DatabaseFailoverManager {
    
    @Autowired
    private DataSource masterDataSource;
    
    @Autowired
    private DataSource slaveDataSource;
    
    @Autowired
    private RedisTemplate<String, Object> redisTemplate;
    
    private volatile boolean masterAvailable = true;
    
    /**
     * 数据库健康检查
     */
    @Scheduled(fixedDelay = 5000)
    public void checkDatabaseHealth() {
        try {
            // 检查主库连接
            Connection connection = masterDataSource.getConnection();
            PreparedStatement statement = connection.prepareStatement("SELECT 1");
            ResultSet resultSet = statement.executeQuery();
            
            if (resultSet.next() && resultSet.getInt(1) == 1) {
                if (!masterAvailable) {
                    log.info("Master database is back online");
                    masterAvailable = true;
                    // 通知应用切换回主库
                    notifyDatabaseSwitch("master");
                }
            }
            
            resultSet.close();
            statement.close();
            connection.close();
            
        } catch (Exception e) {
            if (masterAvailable) {
                log.error("Master database is down, switching to slave", e);
                masterAvailable = false;
                // 通知应用切换到从库
                notifyDatabaseSwitch("slave");
            }
        }
    }
    
    /**
     * 获取可用的数据源
     */
    public DataSource getAvailableDataSource() {
        return masterAvailable ? masterDataSource : slaveDataSource;
    }
    
    /**
     * 通知数据库切换
     */
    private void notifyDatabaseSwitch(String target) {
        try {
            // 发布数据库切换事件
            redisTemplate.convertAndSend("database:switch", target);
            
            // 记录切换日志
            log.info("Database switched to: {}", target);
            
        } catch (Exception e) {
            log.error("Failed to notify database switch", e);
        }
    }
}

/**
 * 动态数据源路由
 */
@Component
public class DynamicDataSource extends AbstractRoutingDataSource {
    
    @Autowired
    private DatabaseFailoverManager failoverManager;
    
    @Override
    protected Object determineCurrentLookupKey() {
        return failoverManager.masterAvailable ? "master" : "slave";
    }
    
    @PostConstruct
    public void init() {
        Map<Object, Object> targetDataSources = new HashMap<>();
        targetDataSources.put("master", failoverManager.masterDataSource);
        targetDataSources.put("slave", failoverManager.slaveDataSource);
        
        setTargetDataSources(targetDataSources);
        setDefaultTargetDataSource(failoverManager.masterDataSource);
        afterPropertiesSet();
    }
}
```

### 2. 服务故障转移

```java
@Component
public class ServiceFailoverManager {
    
    @Autowired
    private DiscoveryClient discoveryClient;
    
    @Autowired
    private LoadBalancerClient loadBalancerClient;
    
    private final Map<String, List<ServiceInstance>> serviceCache = new ConcurrentHashMap<>();
    private final Map<String, ServiceInstance> activeInstances = new ConcurrentHashMap<>();
    
    /**
     * 服务健康检查
     */
    @Scheduled(fixedDelay = 10000)
    public void checkServiceHealth() {
        List<String> services = discoveryClient.getServices();
        
        for (String serviceName : services) {
            List<ServiceInstance> instances = discoveryClient.getInstances(serviceName);
            serviceCache.put(serviceName, instances);
            
            // 检查当前活跃实例是否健康
            ServiceInstance activeInstance = activeInstances.get(serviceName);
            if (activeInstance != null && !isInstanceHealthy(activeInstance)) {
                // 切换到健康的实例
                ServiceInstance healthyInstance = findHealthyInstance(instances);
                if (healthyInstance != null) {
                    activeInstances.put(serviceName, healthyInstance);
                    log.info("Service {} switched from {} to {}", 
                        serviceName, activeInstance.getUri(), healthyInstance.getUri());
                }
            }
        }
    }
    
    /**
     * 检查实例健康状态
     */
    private boolean isInstanceHealthy(ServiceInstance instance) {
        try {
            RestTemplate restTemplate = new RestTemplate();
            restTemplate.setRequestFactory(new SimpleClientHttpRequestFactory());
            ((SimpleClientHttpRequestFactory) restTemplate.getRequestFactory()).setConnectTimeout(3000);
            ((SimpleClientHttpRequestFactory) restTemplate.getRequestFactory()).setReadTimeout(5000);
            
            String healthUrl = instance.getUri() + "/actuator/health";
            ResponseEntity<Map> response = restTemplate.getForEntity(healthUrl, Map.class);
            
            return response.getStatusCode().is2xxSuccessful() && 
                   "UP".equals(((Map) response.getBody().get("status")));
                   
        } catch (Exception e) {
            log.warn("Health check failed for instance: {}", instance.getUri(), e);
            return false;
        }
    }
    
    /**
     * 查找健康的实例
     */
    private ServiceInstance findHealthyInstance(List<ServiceInstance> instances) {
        for (ServiceInstance instance : instances) {
            if (isInstanceHealthy(instance)) {
                return instance;
            }
        }
        return null;
    }
    
    /**
     * 获取可用的服务实例
     */
    public ServiceInstance getAvailableInstance(String serviceName) {
        ServiceInstance activeInstance = activeInstances.get(serviceName);
        if (activeInstance != null && isInstanceHealthy(activeInstance)) {
            return activeInstance;
        }
        
        // 如果当前实例不可用，查找新的健康实例
        List<ServiceInstance> instances = serviceCache.get(serviceName);
        if (instances != null) {
            ServiceInstance healthyInstance = findHealthyInstance(instances);
            if (healthyInstance != null) {
                activeInstances.put(serviceName, healthyInstance);
                return healthyInstance;
            }
        }
        
        return null;
    }
}
```

### 3. 自动故障恢复

```java
@Component
public class AutoRecoveryManager {
    
    @Autowired
    private DatabaseFailoverManager databaseFailoverManager;
    
    @Autowired
    private ServiceFailoverManager serviceFailoverManager;
    
    @Autowired
    private NotificationService notificationService;
    
    /**
     * 故障恢复检查
     */
    @Scheduled(fixedDelay = 30000)
    public void checkRecovery() {
        // 检查数据库恢复
        checkDatabaseRecovery();
        
        // 检查服务恢复
        checkServiceRecovery();
        
        // 检查缓存恢复
        checkCacheRecovery();
    }
    
    /**
     * 数据库恢复检查
     */
    private void checkDatabaseRecovery() {
        if (!databaseFailoverManager.masterAvailable) {
            try {
                // 尝试连接主库
                Connection connection = databaseFailoverManager.masterDataSource.getConnection();
                PreparedStatement statement = connection.prepareStatement("SELECT 1");
                ResultSet resultSet = statement.executeQuery();
                
                if (resultSet.next()) {
                    log.info("Master database recovered, initiating failback");
                    
                    // 数据同步检查
                    if (checkDataConsistency()) {
                        databaseFailoverManager.masterAvailable = true;
                        notificationService.sendAlert("Database master recovered and failed back");
                    } else {
                        log.warn("Data inconsistency detected, manual intervention required");
                        notificationService.sendAlert("Database master recovered but data inconsistency detected");
                    }
                }
                
                resultSet.close();
                statement.close();
                connection.close();
                
            } catch (Exception e) {
                log.debug("Master database still not available: {}", e.getMessage());
            }
        }
    }
    
    /**
     * 服务恢复检查
     */
    private void checkServiceRecovery() {
        List<String> services = Arrays.asList("imsi-service", "billing-service", "user-service");
        
        for (String serviceName : services) {
            List<ServiceInstance> instances = serviceFailoverManager.serviceCache.get(serviceName);
            if (instances != null) {
                for (ServiceInstance instance : instances) {
                    if (serviceFailoverManager.isInstanceHealthy(instance)) {
                        ServiceInstance currentActive = serviceFailoverManager.activeInstances.get(serviceName);
                        if (currentActive == null || !currentActive.equals(instance)) {
                            // 发现更好的实例，进行切换
                            serviceFailoverManager.activeInstances.put(serviceName, instance);
                            log.info("Service {} recovered to instance: {}", serviceName, instance.getUri());
                        }
                        break;
                    }
                }
            }
        }
    }
    
    /**
     * 缓存恢复检查
     */
    private void checkCacheRecovery() {
        try {
            // 检查Redis连接
            redisTemplate.opsForValue().get("health:check");
            log.debug("Cache is healthy");
            
        } catch (Exception e) {
            log.warn("Cache is still not available: {}", e.getMessage());
            
            // 尝试重新初始化连接
            try {
                redisTemplate.getConnectionFactory().getConnection().ping();
                log.info("Cache connection recovered");
                
            } catch (Exception ex) {
                log.error("Failed to recover cache connection", ex);
            }
        }
    }
    
    /**
     * 数据一致性检查
     */
    private boolean checkDataConsistency() {
        try {
            // 检查主从数据一致性
            // 这里可以实现具体的数据一致性检查逻辑
            return true;
            
        } catch (Exception e) {
            log.error("Data consistency check failed", e);
            return false;
        }
    }
}
```

## 监控告警系统

### 1. Prometheus监控配置

```yaml
# prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "nsrs_rules.yml"

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093

scrape_configs:
  - job_name: 'nsrs-application'
    static_configs:
      - targets: ['app1:8080', 'app2:8080', 'app3:8080']
    metrics_path: '/actuator/prometheus'
    scrape_interval: 10s
    
  - job_name: 'nsrs-database'
    static_configs:
      - targets: ['db-exporter:9104']
    scrape_interval: 30s
    
  - job_name: 'nsrs-redis'
    static_configs:
      - targets: ['redis-exporter:9121']
    scrape_interval: 30s
    
  - job_name: 'nsrs-nginx'
    static_configs:
      - targets: ['nginx-exporter:9113']
    scrape_interval: 30s
```

```yaml
# nsrs_rules.yml
groups:
  - name: nsrs.rules
    rules:
      # 应用可用性告警
      - alert: ApplicationDown
        expr: up{job="nsrs-application"} == 0
        for: 30s
        labels:
          severity: critical
        annotations:
          summary: "NSRS Application is down"
          description: "Application {{ $labels.instance }} has been down for more than 30 seconds."
      
      # 高错误率告警
      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.1
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value }} for instance {{ $labels.instance }}."
      
      # 响应时间告警
      - alert: HighResponseTime
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 2
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High response time detected"
          description: "95th percentile response time is {{ $value }}s for {{ $labels.instance }}."
      
      # 数据库连接告警
      - alert: DatabaseConnectionHigh
        expr: mysql_global_status_threads_connected / mysql_global_variables_max_connections > 0.8
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "Database connection usage is high"
          description: "Database connection usage is {{ $value | humanizePercentage }}."
      
      # Redis内存告警
      - alert: RedisMemoryHigh
        expr: redis_memory_used_bytes / redis_memory_max_bytes > 0.9
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Redis memory usage is high"
          description: "Redis memory usage is {{ $value | humanizePercentage }}."
      
      # 磁盘空间告警
      - alert: DiskSpaceHigh
        expr: (node_filesystem_size_bytes - node_filesystem_free_bytes) / node_filesystem_size_bytes > 0.85
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Disk space usage is high"
          description: "Disk space usage is {{ $value | humanizePercentage }} on {{ $labels.instance }}."
```

### 2. AlertManager配置

```yaml
# alertmanager.yml
global:
  smtp_smarthost: 'smtp.example.com:587'
  smtp_from: 'alerts@example.com'
  smtp_auth_username: 'alerts@example.com'
  smtp_auth_password: 'password'

route:
  group_by: ['alertname']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 1h
  receiver: 'web.hook'
  routes:
    - match:
        severity: critical
      receiver: 'critical-alerts'
    - match:
        severity: warning
      receiver: 'warning-alerts'

receivers:
  - name: 'web.hook'
    webhook_configs:
      - url: 'http://webhook-server:8080/alerts'
        
  - name: 'critical-alerts'
    email_configs:
      - to: 'ops-team@example.com'
        subject: '[CRITICAL] NSRS Alert: {{ .GroupLabels.alertname }}'
        body: |
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Instance: {{ .Labels.instance }}
          Severity: {{ .Labels.severity }}
          {{ end }}
    webhook_configs:
      - url: 'http://dingtalk-webhook:8080/critical'
        
  - name: 'warning-alerts'
    email_configs:
      - to: 'dev-team@example.com'
        subject: '[WARNING] NSRS Alert: {{ .GroupLabels.alertname }}'
        body: |
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Instance: {{ .Labels.instance }}
          {{ end }}

inhibit_rules:
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'instance']
```

### 3. 自定义监控指标

```java
@Component
public class CustomMetrics {
    
    private final Counter imsiAllocationCounter;
    private final Timer imsiAllocationTimer;
    private final Gauge activeConnectionsGauge;
    private final Histogram requestSizeHistogram;
    
    public CustomMetrics(MeterRegistry meterRegistry) {
        // IMSI分配计数器
        this.imsiAllocationCounter = Counter.builder("nsrs.imsi.allocation.total")
            .description("Total number of IMSI allocations")
            .tag("status", "success")
            .register(meterRegistry);
            
        // IMSI分配耗时
        this.imsiAllocationTimer = Timer.builder("nsrs.imsi.allocation.duration")
            .description("IMSI allocation duration")
            .register(meterRegistry);
            
        // 活跃连接数
        this.activeConnectionsGauge = Gauge.builder("nsrs.connections.active")
            .description("Number of active connections")
            .register(meterRegistry, this, CustomMetrics::getActiveConnections);
            
        // 请求大小分布
        this.requestSizeHistogram = Histogram.builder("nsrs.request.size")
            .description("Request size distribution")
            .buckets(1024, 4096, 16384, 65536, 262144)
            .register(meterRegistry);
    }
    
    public void recordImsiAllocation(String status) {
        imsiAllocationCounter.increment(Tags.of("status", status));
    }
    
    public Timer.Sample startImsiAllocationTimer() {
        return Timer.start(imsiAllocationTimer);
    }
    
    public void recordRequestSize(long size) {
        requestSizeHistogram.record(size);
    }
    
    private double getActiveConnections() {
        // 获取活跃连接数的逻辑
        return 0.0;
    }
}

@RestController
public class ImsiResourceController {
    
    @Autowired
    private ImsiResourceService imsiResourceService;
    
    @Autowired
    private CustomMetrics customMetrics;
    
    @PostMapping("/allocate")
    public ResponseEntity<ImsiAllocationResponse> allocateImsi(@RequestBody ImsiAllocationRequest request) {
        Timer.Sample sample = customMetrics.startImsiAllocationTimer();
        
        try {
            ImsiAllocationResponse response = imsiResourceService.allocateImsi(request);
            customMetrics.recordImsiAllocation("success");
            return ResponseEntity.ok(response);
            
        } catch (Exception e) {
            customMetrics.recordImsiAllocation("failure");
            throw e;
            
        } finally {
            sample.stop();
        }
    }
}
```

## 性能优化策略

### 1. 连接池优化

```yaml
# application.yml
spring:
  datasource:
    hikari:
      maximum-pool-size: 20
      minimum-idle: 5
      idle-timeout: 300000
      max-lifetime: 1800000
      connection-timeout: 30000
      validation-timeout: 5000
      leak-detection-threshold: 60000
      
  redis:
    lettuce:
      pool:
        max-active: 20
        max-idle: 10
        min-idle: 5
        max-wait: 5000ms
      timeout: 5000ms
```

### 2. JVM调优

```bash
# JVM启动参数
JAVA_OPTS="-Xms2g -Xmx4g \
  -XX:+UseG1GC \
  -XX:MaxGCPauseMillis=200 \
  -XX:+UnlockExperimentalVMOptions \
  -XX:+UseStringDeduplication \
  -XX:+PrintGC \
  -XX:+PrintGCDetails \
  -XX:+PrintGCTimeStamps \
  -Xloggc:/var/log/nsrs/gc.log \
  -XX:+UseGCLogFileRotation \
  -XX:NumberOfGCLogFiles=5 \
  -XX:GCLogFileSize=100M \
  -XX:+HeapDumpOnOutOfMemoryError \
  -XX:HeapDumpPath=/var/log/nsrs/heapdump.hprof"
```

### 3. 缓存策略优化

```java
@Service
public class CacheOptimizationService {
    
    @Autowired
    private RedisTemplate<String, Object> redisTemplate;
    
    @Autowired
    private CacheManager cacheManager;
    
    /**
     * 多级缓存策略
     */
    public ImsiResource getImsiResource(String imsi) {
        // L1缓存：本地缓存
        Cache localCache = cacheManager.getCache("imsiResource");
        ImsiResource resource = localCache.get(imsi, ImsiResource.class);
        
        if (resource != null) {
            return resource;
        }
        
        // L2缓存：Redis缓存
        resource = (ImsiResource) redisTemplate.opsForValue().get("imsi:" + imsi);
        if (resource != null) {
            // 回填本地缓存
            localCache.put(imsi, resource);
            return resource;
        }
        
        // L3：数据库查询
        resource = imsiResourceMapper.selectByImsi(imsi);
        if (resource != null) {
            // 回填缓存
            redisTemplate.opsForValue().set("imsi:" + imsi, resource, Duration.ofHours(1));
            localCache.put(imsi, resource);
        }
        
        return resource;
    }
    
    /**
     * 缓存预热
     */
    @EventListener(ApplicationReadyEvent.class)
    public void warmupCache() {
        log.info("Starting cache warmup");
        
        // 预加载热点数据
        List<ImsiResource> hotResources = imsiResourceMapper.selectHotResources(1000);
        
        for (ImsiResource resource : hotResources) {
            redisTemplate.opsForValue().set("imsi:" + resource.getImsi(), resource, Duration.ofHours(2));
        }
        
        log.info("Cache warmup completed, loaded {} resources", hotResources.size());
    }
}
```

## 总结

本高可用架构设计指南涵盖了NSRS号卡资源管理系统的关键高可用组件：

1. **负载均衡**: 四层和七层负载均衡配置，支持多种负载均衡算法和健康检查
2. **容灾备份**: 数据库主从复制、Redis哨兵模式、文件存储备份
3. **故障转移**: 自动故障检测和切换机制，支持数据库和服务的故障转移
4. **监控告警**: 基于Prometheus和AlertManager的全方位监控告警系统
5. **性能优化**: 连接池优化、JVM调优、多级缓存策略

通过这些技术方案的实施，可以确保NSRS系统达到99.99%的可用性目标，为电信运营商提供稳定可靠的号卡资源管理服务。