# NSRS号卡资源管理系统 - 高可用架构设计详解

## 概述

高可用架构是确保NSRS号卡资源管理系统在面对各种故障时能够持续提供服务的关键设计。本文档详细阐述了系统的容灾方案、故障转移机制，并提供了完整的实施Demo。

## 高可用架构核心组件

### 1. 高可用等级枚举

```java
/**
 * 高可用等级枚举
 * 定义系统不同组件的可用性要求
 */
public enum HighAvailabilityLevel {
    BASIC("基础级", 99.0, "基本的故障恢复能力"),
    STANDARD("标准级", 99.9, "标准的高可用保障"),
    HIGH("高级", 99.99, "高级别的可用性保障"),
    CRITICAL("关键级", 99.999, "关键业务的极高可用性"),
    ULTRA("超高级", 99.9999, "超高可用性要求");
    
    private final String description;
    private final double availabilityPercentage;
    private final String requirement;
    
    HighAvailabilityLevel(String description, double availabilityPercentage, String requirement) {
        this.description = description;
        this.availabilityPercentage = availabilityPercentage;
        this.requirement = requirement;
    }
    
    // getters...
}
```

### 2. 故障转移策略枚举

```java
/**
 * 故障转移策略枚举
 * 定义不同的故障转移方式
 */
public enum FailoverStrategy {
    ACTIVE_PASSIVE("主备模式", "一个主节点处理请求，备节点待机"),
    ACTIVE_ACTIVE("双活模式", "多个节点同时处理请求"),
    LOAD_BALANCING("负载均衡", "请求分散到多个健康节点"),
    CIRCUIT_BREAKER("熔断器", "快速失败并切换到备用服务"),
    GRACEFUL_DEGRADATION("优雅降级", "部分功能降级但核心服务可用"),
    AUTO_SCALING("自动扩缩容", "根据负载自动调整资源");
    
    private final String description;
    private final String detail;
    
    FailoverStrategy(String description, String detail) {
        this.description = description;
        this.detail = detail;
    }
    
    // getters...
}
```

### 3. 容灾级别枚举

```java
/**
 * 容灾级别枚举
 * 定义不同的容灾恢复能力
 */
public enum DisasterRecoveryLevel {
    RTO_LEVEL_1("RTO-1级", 24, 4, "24小时内恢复，最多丢失4小时数据"),
    RTO_LEVEL_2("RTO-2级", 12, 2, "12小时内恢复，最多丢失2小时数据"),
    RTO_LEVEL_3("RTO-3级", 4, 1, "4小时内恢复，最多丢失1小时数据"),
    RTO_LEVEL_4("RTO-4级", 1, 0.25, "1小时内恢复，最多丢失15分钟数据"),
    RTO_LEVEL_5("RTO-5级", 0.25, 0.083, "15分钟内恢复，最多丢失5分钟数据"),
    RTO_LEVEL_6("RTO-6级", 0.083, 0, "5分钟内恢复，零数据丢失");
    
    private final String description;
    private final double rtoHours; // Recovery Time Objective (恢复时间目标)
    private final double rpoHours; // Recovery Point Objective (恢复点目标)
    private final String requirement;
    
    DisasterRecoveryLevel(String description, double rtoHours, double rpoHours, String requirement) {
        this.description = description;
        this.rtoHours = rtoHours;
        this.rpoHours = rpoHours;
        this.requirement = requirement;
    }
    
    // getters...
}
```

## 核心实体类设计

### 1. 高可用配置实体

```java
/**
 * 高可用配置实体
 * 定义系统组件的高可用参数
 */
@Entity
@Table(name = "ha_config")
public class HighAvailabilityConfig {
    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    private Long id;
    
    @Column(name = "component_name", nullable = false)
    private String componentName; // 组件名称
    
    @Enumerated(EnumType.STRING)
    @Column(name = "ha_level", nullable = false)
    private HighAvailabilityLevel haLevel; // 高可用等级
    
    @Enumerated(EnumType.STRING)
    @Column(name = "failover_strategy", nullable = false)
    private FailoverStrategy failoverStrategy; // 故障转移策略
    
    @Enumerated(EnumType.STRING)
    @Column(name = "dr_level", nullable = false)
    private DisasterRecoveryLevel drLevel; // 容灾级别
    
    @Column(name = "health_check_interval")
    private Integer healthCheckInterval; // 健康检查间隔(秒)
    
    @Column(name = "failover_timeout")
    private Integer failoverTimeout; // 故障转移超时(秒)
    
    @Column(name = "max_retry_attempts")
    private Integer maxRetryAttempts; // 最大重试次数
    
    @Column(name = "circuit_breaker_threshold")
    private Integer circuitBreakerThreshold; // 熔断器阈值
    
    @Column(name = "auto_scaling_enabled")
    private Boolean autoScalingEnabled; // 是否启用自动扩缩容
    
    @Column(name = "min_instances")
    private Integer minInstances; // 最小实例数
    
    @Column(name = "max_instances")
    private Integer maxInstances; // 最大实例数
    
    @Column(name = "backup_enabled")
    private Boolean backupEnabled; // 是否启用备份
    
    @Column(name = "backup_interval")
    private Integer backupInterval; // 备份间隔(小时)
    
    @Column(name = "backup_retention_days")
    private Integer backupRetentionDays; // 备份保留天数
    
    @Column(name = "monitoring_enabled")
    private Boolean monitoringEnabled; // 是否启用监控
    
    @Column(name = "alert_enabled")
    private Boolean alertEnabled; // 是否启用告警
    
    @Column(name = "created_at")
    private LocalDateTime createdAt;
    
    @Column(name = "updated_at")
    private LocalDateTime updatedAt;
    
    // constructors, getters, setters...
}
```

### 2. 故障事件实体

```java
/**
 * 故障事件实体
 * 记录系统故障和恢复事件
 */
@Entity
@Table(name = "failure_event")
public class FailureEvent {
    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    private Long id;
    
    @Column(name = "event_id", unique = true, nullable = false)
    private String eventId; // 事件唯一标识
    
    @Column(name = "component_name", nullable = false)
    private String componentName; // 故障组件名称
    
    @Column(name = "failure_type", nullable = false)
    private String failureType; // 故障类型
    
    @Column(name = "severity_level", nullable = false)
    private String severityLevel; // 严重程度
    
    @Column(name = "failure_description", columnDefinition = "TEXT")
    private String failureDescription; // 故障描述
    
    @Column(name = "failure_start_time", nullable = false)
    private LocalDateTime failureStartTime; // 故障开始时间
    
    @Column(name = "failure_end_time")
    private LocalDateTime failureEndTime; // 故障结束时间
    
    @Column(name = "detection_time", nullable = false)
    private LocalDateTime detectionTime; // 故障检测时间
    
    @Column(name = "recovery_time")
    private LocalDateTime recoveryTime; // 恢复时间
    
    @Column(name = "downtime_minutes")
    private Long downtimeMinutes; // 停机时间(分钟)
    
    @Column(name = "affected_users")
    private Long affectedUsers; // 受影响用户数
    
    @Column(name = "data_loss_amount")
    private String dataLossAmount; // 数据丢失量
    
    @Enumerated(EnumType.STRING)
    @Column(name = "failover_strategy_used")
    private FailoverStrategy failoverStrategyUsed; // 使用的故障转移策略
    
    @Column(name = "auto_recovery")
    private Boolean autoRecovery; // 是否自动恢复
    
    @Column(name = "manual_intervention")
    private Boolean manualIntervention; // 是否需要人工干预
    
    @Column(name = "root_cause", columnDefinition = "TEXT")
    private String rootCause; // 根本原因
    
    @Column(name = "resolution_actions", columnDefinition = "TEXT")
    private String resolutionActions; // 解决措施
    
    @Column(name = "lessons_learned", columnDefinition = "TEXT")
    private String lessonsLearned; // 经验教训
    
    @Column(name = "status")
    private String status; // 事件状态: OPEN, IN_PROGRESS, RESOLVED, CLOSED
    
    @Column(name = "created_at")
    private LocalDateTime createdAt;
    
    @Column(name = "updated_at")
    private LocalDateTime updatedAt;
    
    // constructors, getters, setters...
}
```

### 3. 健康检查结果实体

```java
/**
 * 健康检查结果实体
 * 记录系统组件的健康状态
 */
@Entity
@Table(name = "health_check_result")
public class HealthCheckResult {
    @Id
    @GeneratedValue(strategy = GenerationType.IDENTITY)
    private Long id;
    
    @Column(name = "component_name", nullable = false)
    private String componentName; // 组件名称
    
    @Column(name = "instance_id", nullable = false)
    private String instanceId; // 实例标识
    
    @Column(name = "check_time", nullable = false)
    private LocalDateTime checkTime; // 检查时间
    
    @Column(name = "status", nullable = false)
    private String status; // 健康状态: HEALTHY, UNHEALTHY, DEGRADED, UNKNOWN
    
    @Column(name = "response_time_ms")
    private Long responseTimeMs; // 响应时间(毫秒)
    
    @Column(name = "cpu_usage_percent")
    private Double cpuUsagePercent; // CPU使用率
    
    @Column(name = "memory_usage_percent")
    private Double memoryUsagePercent; // 内存使用率
    
    @Column(name = "disk_usage_percent")
    private Double diskUsagePercent; // 磁盘使用率
    
    @Column(name = "network_latency_ms")
    private Long networkLatencyMs; // 网络延迟
    
    @Column(name = "active_connections")
    private Integer activeConnections; // 活跃连接数
    
    @Column(name = "error_rate_percent")
    private Double errorRatePercent; // 错误率
    
    @Column(name = "throughput_per_second")
    private Double throughputPerSecond; // 吞吐量
    
    @Column(name = "health_score")
    private Double healthScore; // 健康评分(0-100)
    
    @Column(name = "check_details", columnDefinition = "TEXT")
    private String checkDetails; // 检查详情
    
    @Column(name = "alerts_triggered")
    private String alertsTriggered; // 触发的告警
    
    // constructors, getters, setters...
}
```

## 高可用服务实现

### 1. 高可用管理服务

```java
/**
 * 高可用管理服务
 * 负责系统高可用配置和故障处理
 */
@Service
@Slf4j
public class HighAvailabilityService {
    
    @Autowired
    private HighAvailabilityConfigRepository haConfigRepository;
    
    @Autowired
    private FailureEventRepository failureEventRepository;
    
    @Autowired
    private HealthCheckResultRepository healthCheckRepository;
    
    @Autowired
    private LoadBalancerService loadBalancerService;
    
    @Autowired
    private CircuitBreakerService circuitBreakerService;
    
    @Autowired
    private AutoScalingService autoScalingService;
    
    @Autowired
    private BackupService backupService;
    
    @Autowired
    private AlertService alertService;
    
    /**
     * 创建高可用配置
     */
    public HighAvailabilityConfig createHAConfig(String componentName, 
                                                  HighAvailabilityLevel haLevel,
                                                  FailoverStrategy failoverStrategy,
                                                  DisasterRecoveryLevel drLevel) {
        log.info("Creating HA config for component: {}", componentName);
        
        HighAvailabilityConfig config = new HighAvailabilityConfig();
        config.setComponentName(componentName);
        config.setHaLevel(haLevel);
        config.setFailoverStrategy(failoverStrategy);
        config.setDrLevel(drLevel);
        
        // 根据高可用等级设置默认参数
        setDefaultConfigByLevel(config, haLevel);
        
        config.setCreatedAt(LocalDateTime.now());
        config.setUpdatedAt(LocalDateTime.now());
        
        HighAvailabilityConfig savedConfig = haConfigRepository.save(config);
        
        // 初始化组件的高可用机制
        initializeHAMechanisms(savedConfig);
        
        log.info("HA config created successfully for component: {}", componentName);
        return savedConfig;
    }
    
    /**
     * 处理组件故障
     */
    public void handleComponentFailure(String componentName, String failureType, 
                                       String failureDescription) {
        log.error("Component failure detected: {} - {}", componentName, failureType);
        
        // 记录故障事件
        FailureEvent failureEvent = createFailureEvent(componentName, failureType, failureDescription);
        
        // 获取组件的高可用配置
        HighAvailabilityConfig config = haConfigRepository.findByComponentName(componentName)
            .orElseThrow(() -> new RuntimeException("HA config not found for component: " + componentName));
        
        // 执行故障转移策略
        executeFailoverStrategy(config, failureEvent);
        
        // 发送告警
        if (config.getAlertEnabled()) {
            alertService.sendFailureAlert(failureEvent);
        }
        
        // 触发自动恢复机制
        triggerAutoRecovery(config, failureEvent);
    }
    
    /**
     * 执行健康检查
     */
    @Scheduled(fixedDelay = 30000) // 每30秒执行一次
    public void performHealthCheck() {
        List<HighAvailabilityConfig> configs = haConfigRepository.findAll();
        
        for (HighAvailabilityConfig config : configs) {
            try {
                HealthCheckResult result = checkComponentHealth(config.getComponentName());
                healthCheckRepository.save(result);
                
                // 分析健康状态并采取行动
                analyzeHealthStatus(config, result);
                
            } catch (Exception e) {
                log.error("Health check failed for component: {}", config.getComponentName(), e);
                handleComponentFailure(config.getComponentName(), "HEALTH_CHECK_FAILURE", e.getMessage());
            }
        }
    }
    
    /**
     * 执行故障转移策略
     */
    private void executeFailoverStrategy(HighAvailabilityConfig config, FailureEvent failureEvent) {
        log.info("Executing failover strategy: {} for component: {}", 
                config.getFailoverStrategy(), config.getComponentName());
        
        switch (config.getFailoverStrategy()) {
            case ACTIVE_PASSIVE:
                executeActivePassiveFailover(config, failureEvent);
                break;
            case ACTIVE_ACTIVE:
                executeActiveActiveFailover(config, failureEvent);
                break;
            case LOAD_BALANCING:
                executeLoadBalancingFailover(config, failureEvent);
                break;
            case CIRCUIT_BREAKER:
                executeCircuitBreakerFailover(config, failureEvent);
                break;
            case GRACEFUL_DEGRADATION:
                executeGracefulDegradation(config, failureEvent);
                break;
            case AUTO_SCALING:
                executeAutoScalingFailover(config, failureEvent);
                break;
            default:
                log.warn("Unknown failover strategy: {}", config.getFailoverStrategy());
        }
        
        // 更新故障事件
        failureEvent.setFailoverStrategyUsed(config.getFailoverStrategy());
        failureEventRepository.save(failureEvent);
    }
    
    /**
     * 主备模式故障转移
     */
    private void executeActivePassiveFailover(HighAvailabilityConfig config, FailureEvent failureEvent) {
        log.info("Executing active-passive failover for: {}", config.getComponentName());
        
        try {
            // 1. 停止故障实例
            stopFailedInstance(config.getComponentName(), failureEvent.getEventId());
            
            // 2. 启动备用实例
            String backupInstanceId = startBackupInstance(config.getComponentName());
            
            // 3. 更新负载均衡器配置
            loadBalancerService.updateBackendServers(config.getComponentName(), 
                Arrays.asList(backupInstanceId));
            
            // 4. 验证故障转移结果
            boolean failoverSuccess = verifyFailoverSuccess(config.getComponentName());
            
            if (failoverSuccess) {
                log.info("Active-passive failover completed successfully for: {}", config.getComponentName());
                failureEvent.setAutoRecovery(true);
            } else {
                log.error("Active-passive failover failed for: {}", config.getComponentName());
                failureEvent.setManualIntervention(true);
            }
            
        } catch (Exception e) {
            log.error("Active-passive failover failed for: {}", config.getComponentName(), e);
            failureEvent.setManualIntervention(true);
        }
    }
    
    /**
     * 双活模式故障转移
     */
    private void executeActiveActiveFailover(HighAvailabilityConfig config, FailureEvent failureEvent) {
        log.info("Executing active-active failover for: {}", config.getComponentName());
        
        try {
            // 1. 从负载均衡器中移除故障实例
            List<String> healthyInstances = getHealthyInstances(config.getComponentName());
            loadBalancerService.updateBackendServers(config.getComponentName(), healthyInstances);
            
            // 2. 如果健康实例不足，启动新实例
            if (healthyInstances.size() < config.getMinInstances()) {
                int instancesToStart = config.getMinInstances() - healthyInstances.size();
                for (int i = 0; i < instancesToStart; i++) {
                    String newInstanceId = startNewInstance(config.getComponentName());
                    healthyInstances.add(newInstanceId);
                }
                loadBalancerService.updateBackendServers(config.getComponentName(), healthyInstances);
            }
            
            // 3. 验证故障转移结果
            boolean failoverSuccess = verifyFailoverSuccess(config.getComponentName());
            
            if (failoverSuccess) {
                log.info("Active-active failover completed successfully for: {}", config.getComponentName());
                failureEvent.setAutoRecovery(true);
            } else {
                log.error("Active-active failover failed for: {}", config.getComponentName());
                failureEvent.setManualIntervention(true);
            }
            
        } catch (Exception e) {
            log.error("Active-active failover failed for: {}", config.getComponentName(), e);
            failureEvent.setManualIntervention(true);
        }
    }
    
    /**
     * 负载均衡故障转移
     */
    private void executeLoadBalancingFailover(HighAvailabilityConfig config, FailureEvent failureEvent) {
        log.info("Executing load balancing failover for: {}", config.getComponentName());
        
        try {
            // 1. 更新负载均衡器健康检查
            loadBalancerService.updateHealthCheck(config.getComponentName(), 
                config.getHealthCheckInterval());
            
            // 2. 自动移除不健康的实例
            loadBalancerService.enableAutoRemoveUnhealthyInstances(config.getComponentName());
            
            // 3. 调整负载均衡算法
            loadBalancerService.updateLoadBalancingAlgorithm(config.getComponentName(), 
                "WEIGHTED_ROUND_ROBIN");
            
            failureEvent.setAutoRecovery(true);
            log.info("Load balancing failover completed for: {}", config.getComponentName());
            
        } catch (Exception e) {
            log.error("Load balancing failover failed for: {}", config.getComponentName(), e);
            failureEvent.setManualIntervention(true);
        }
    }
    
    /**
     * 熔断器故障转移
     */
    private void executeCircuitBreakerFailover(HighAvailabilityConfig config, FailureEvent failureEvent) {
        log.info("Executing circuit breaker failover for: {}", config.getComponentName());
        
        try {
            // 1. 激活熔断器
            circuitBreakerService.activateCircuitBreaker(config.getComponentName(), 
                config.getCircuitBreakerThreshold());
            
            // 2. 切换到备用服务
            circuitBreakerService.switchToFallbackService(config.getComponentName());
            
            // 3. 设置自动恢复检测
            circuitBreakerService.enableAutoRecoveryDetection(config.getComponentName(), 
                config.getHealthCheckInterval());
            
            failureEvent.setAutoRecovery(true);
            log.info("Circuit breaker failover completed for: {}", config.getComponentName());
            
        } catch (Exception e) {
            log.error("Circuit breaker failover failed for: {}", config.getComponentName(), e);
            failureEvent.setManualIntervention(true);
        }
    }
    
    /**
     * 优雅降级
     */
    private void executeGracefulDegradation(HighAvailabilityConfig config, FailureEvent failureEvent) {
        log.info("Executing graceful degradation for: {}", config.getComponentName());
        
        try {
            // 1. 识别核心功能和非核心功能
            List<String> coreFunctions = identifyCoreFunctions(config.getComponentName());
            List<String> nonCoreFunctions = identifyNonCoreFunctions(config.getComponentName());
            
            // 2. 禁用非核心功能
            disableNonCoreFunctions(config.getComponentName(), nonCoreFunctions);
            
            // 3. 确保核心功能正常运行
            ensureCoreFunctionsAvailable(config.getComponentName(), coreFunctions);
            
            // 4. 通知用户服务降级
            notifyServiceDegradation(config.getComponentName(), nonCoreFunctions);
            
            failureEvent.setAutoRecovery(true);
            log.info("Graceful degradation completed for: {}", config.getComponentName());
            
        } catch (Exception e) {
            log.error("Graceful degradation failed for: {}", config.getComponentName(), e);
            failureEvent.setManualIntervention(true);
        }
    }
    
    /**
     * 自动扩缩容故障转移
     */
    private void executeAutoScalingFailover(HighAvailabilityConfig config, FailureEvent failureEvent) {
        log.info("Executing auto scaling failover for: {}", config.getComponentName());
        
        try {
            // 1. 分析当前负载和实例状态
            int currentInstances = getCurrentInstanceCount(config.getComponentName());
            int healthyInstances = getHealthyInstanceCount(config.getComponentName());
            double currentLoad = getCurrentLoadPercentage(config.getComponentName());
            
            // 2. 计算需要的实例数
            int requiredInstances = calculateRequiredInstances(currentLoad, healthyInstances, 
                config.getMinInstances(), config.getMaxInstances());
            
            // 3. 执行扩容
            if (requiredInstances > currentInstances) {
                autoScalingService.scaleOut(config.getComponentName(), 
                    requiredInstances - currentInstances);
            }
            
            // 4. 等待新实例就绪
            waitForInstancesReady(config.getComponentName(), requiredInstances);
            
            failureEvent.setAutoRecovery(true);
            log.info("Auto scaling failover completed for: {}", config.getComponentName());
            
        } catch (Exception e) {
            log.error("Auto scaling failover failed for: {}", config.getComponentName(), e);
            failureEvent.setManualIntervention(true);
        }
    }
    
    /**
     * 检查组件健康状态
     */
    private HealthCheckResult checkComponentHealth(String componentName) {
        log.debug("Checking health for component: {}", componentName);
        
        HealthCheckResult result = new HealthCheckResult();
        result.setComponentName(componentName);
        result.setCheckTime(LocalDateTime.now());
        
        try {
            // 1. 检查服务响应
            long startTime = System.currentTimeMillis();
            boolean isResponsive = checkServiceResponsiveness(componentName);
            long responseTime = System.currentTimeMillis() - startTime;
            
            result.setResponseTimeMs(responseTime);
            
            // 2. 检查系统资源
            SystemMetrics metrics = getSystemMetrics(componentName);
            result.setCpuUsagePercent(metrics.getCpuUsage());
            result.setMemoryUsagePercent(metrics.getMemoryUsage());
            result.setDiskUsagePercent(metrics.getDiskUsage());
            result.setNetworkLatencyMs(metrics.getNetworkLatency());
            result.setActiveConnections(metrics.getActiveConnections());
            result.setErrorRatePercent(metrics.getErrorRate());
            result.setThroughputPerSecond(metrics.getThroughput());
            
            // 3. 计算健康评分
            double healthScore = calculateHealthScore(result);
            result.setHealthScore(healthScore);
            
            // 4. 确定健康状态
            String status = determineHealthStatus(healthScore, isResponsive);
            result.setStatus(status);
            
            // 5. 生成检查详情
            result.setCheckDetails(generateHealthCheckDetails(result));
            
            log.debug("Health check completed for {}: status={}, score={}", 
                componentName, status, healthScore);
            
        } catch (Exception e) {
            log.error("Health check failed for component: {}", componentName, e);
            result.setStatus("UNKNOWN");
            result.setCheckDetails("Health check failed: " + e.getMessage());
        }
        
        return result;
    }
    
    // 辅助方法实现...
    
    private void setDefaultConfigByLevel(HighAvailabilityConfig config, HighAvailabilityLevel level) {
        switch (level) {
            case BASIC:
                config.setHealthCheckInterval(300); // 5分钟
                config.setFailoverTimeout(600); // 10分钟
                config.setMaxRetryAttempts(3);
                config.setMinInstances(1);
                config.setMaxInstances(3);
                break;
            case STANDARD:
                config.setHealthCheckInterval(60); // 1分钟
                config.setFailoverTimeout(300); // 5分钟
                config.setMaxRetryAttempts(5);
                config.setMinInstances(2);
                config.setMaxInstances(5);
                break;
            case HIGH:
                config.setHealthCheckInterval(30); // 30秒
                config.setFailoverTimeout(120); // 2分钟
                config.setMaxRetryAttempts(10);
                config.setMinInstances(3);
                config.setMaxInstances(10);
                break;
            case CRITICAL:
                config.setHealthCheckInterval(15); // 15秒
                config.setFailoverTimeout(60); // 1分钟
                config.setMaxRetryAttempts(15);
                config.setMinInstances(5);
                config.setMaxInstances(20);
                break;
            case ULTRA:
                config.setHealthCheckInterval(5); // 5秒
                config.setFailoverTimeout(30); // 30秒
                config.setMaxRetryAttempts(20);
                config.setMinInstances(10);
                config.setMaxInstances(50);
                break;
        }
        
        // 通用默认设置
        config.setCircuitBreakerThreshold(10);
        config.setAutoScalingEnabled(true);
        config.setBackupEnabled(true);
        config.setBackupInterval(24); // 24小时
        config.setBackupRetentionDays(30);
        config.setMonitoringEnabled(true);
        config.setAlertEnabled(true);
    }
    
    private FailureEvent createFailureEvent(String componentName, String failureType, String description) {
        FailureEvent event = new FailureEvent();
        event.setEventId("FAIL_" + System.currentTimeMillis() + "_" + UUID.randomUUID().toString().substring(0, 8));
        event.setComponentName(componentName);
        event.setFailureType(failureType);
        event.setFailureDescription(description);
        event.setFailureStartTime(LocalDateTime.now());
        event.setDetectionTime(LocalDateTime.now());
        event.setSeverityLevel(determineSeverityLevel(failureType));
        event.setStatus("OPEN");
        event.setAutoRecovery(false);
        event.setManualIntervention(false);
        event.setCreatedAt(LocalDateTime.now());
        event.setUpdatedAt(LocalDateTime.now());
        
        return failureEventRepository.save(event);
    }
    
    private String determineSeverityLevel(String failureType) {
        switch (failureType.toUpperCase()) {
            case "SYSTEM_DOWN":
            case "DATABASE_FAILURE":
            case "NETWORK_OUTAGE":
                return "CRITICAL";
            case "SERVICE_DEGRADATION":
            case "HIGH_LATENCY":
            case "MEMORY_LEAK":
                return "HIGH";
            case "HEALTH_CHECK_FAILURE":
            case "TIMEOUT":
                return "MEDIUM";
            default:
                return "LOW";
        }
    }
    
    private double calculateHealthScore(HealthCheckResult result) {
        double score = 100.0;
        
        // CPU使用率影响 (权重: 20%)
        if (result.getCpuUsagePercent() != null) {
            if (result.getCpuUsagePercent() > 90) score -= 20;
            else if (result.getCpuUsagePercent() > 80) score -= 15;
            else if (result.getCpuUsagePercent() > 70) score -= 10;
        }
        
        // 内存使用率影响 (权重: 20%)
        if (result.getMemoryUsagePercent() != null) {
            if (result.getMemoryUsagePercent() > 90) score -= 20;
            else if (result.getMemoryUsagePercent() > 80) score -= 15;
            else if (result.getMemoryUsagePercent() > 70) score -= 10;
        }
        
        // 响应时间影响 (权重: 25%)
        if (result.getResponseTimeMs() != null) {
            if (result.getResponseTimeMs() > 5000) score -= 25;
            else if (result.getResponseTimeMs() > 3000) score -= 20;
            else if (result.getResponseTimeMs() > 1000) score -= 15;
            else if (result.getResponseTimeMs() > 500) score -= 10;
        }
        
        // 错误率影响 (权重: 25%)
        if (result.getErrorRatePercent() != null) {
            if (result.getErrorRatePercent() > 10) score -= 25;
            else if (result.getErrorRatePercent() > 5) score -= 20;
            else if (result.getErrorRatePercent() > 2) score -= 15;
            else if (result.getErrorRatePercent() > 1) score -= 10;
        }
        
        // 磁盘使用率影响 (权重: 10%)
        if (result.getDiskUsagePercent() != null) {
            if (result.getDiskUsagePercent() > 95) score -= 10;
            else if (result.getDiskUsagePercent() > 90) score -= 5;
        }
        
        return Math.max(0, score);
    }
    
    private String determineHealthStatus(double healthScore, boolean isResponsive) {
        if (!isResponsive) {
            return "UNHEALTHY";
        }
        
        if (healthScore >= 90) {
            return "HEALTHY";
        } else if (healthScore >= 70) {
            return "DEGRADED";
        } else {
            return "UNHEALTHY";
        }
    }
}
```

## 容灾方案设计

### 1. 容灾架构模式

#### 同城双活架构

```java
/**
 * 同城双活容灾服务
 * 实现同城两个数据中心的双活部署
 */
@Service
@Slf4j
public class LocalDualActiveDisasterRecoveryService {
    
    @Autowired
    private DataSynchronizationService dataSyncService;
    
    @Autowired
    private TrafficRoutingService trafficRoutingService;
    
    @Autowired
    private HealthMonitoringService healthMonitoringService;
    
    /**
     * 初始化同城双活架构
     */
    public void initializeLocalDualActive() {
        log.info("Initializing local dual-active disaster recovery");
        
        // 1. 配置数据同步
        setupDataSynchronization();
        
        // 2. 配置流量路由
        setupTrafficRouting();
        
        // 3. 启动健康监控
        startHealthMonitoring();
        
        // 4. 配置自动故障转移
        setupAutoFailover();
        
        log.info("Local dual-active disaster recovery initialized successfully");
    }
    
    /**
     * 配置数据同步
     */
    private void setupDataSynchronization() {
        // 配置数据库主主复制
        dataSyncService.setupMasterMasterReplication("datacenter-a", "datacenter-b");
        
        // 配置Redis集群同步
        dataSyncService.setupRedisClusterSync("datacenter-a", "datacenter-b");
        
        // 配置文件存储同步
        dataSyncService.setupFileStorageSync("datacenter-a", "datacenter-b");
    }
    
    /**
     * 配置流量路由
     */
    private void setupTrafficRouting() {
        // 配置DNS轮询
        trafficRoutingService.setupDNSRoundRobin(Arrays.asList(
            "datacenter-a.nsrs.com", "datacenter-b.nsrs.com"));
        
        // 配置负载均衡器
        trafficRoutingService.setupLoadBalancer("WEIGHTED_ROUND_ROBIN", 
            Map.of("datacenter-a", 50, "datacenter-b", 50));
        
        // 配置会话亲和性
        trafficRoutingService.enableSessionAffinity(true);
    }
    
    /**
     * 处理数据中心故障
     */
    public void handleDatacenterFailure(String failedDatacenter) {
        log.error("Datacenter failure detected: {}", failedDatacenter);
        
        String activeDatacenter = failedDatacenter.equals("datacenter-a") ? 
            "datacenter-b" : "datacenter-a";
        
        // 1. 切换所有流量到健康数据中心
        trafficRoutingService.routeAllTrafficTo(activeDatacenter);
        
        // 2. 停止到故障数据中心的数据同步
        dataSyncService.stopSyncToDatacenter(failedDatacenter);
        
        // 3. 启动单数据中心模式
        enableSingleDatacenterMode(activeDatacenter);
        
        // 4. 发送告警
        alertService.sendDatacenterFailureAlert(failedDatacenter, activeDatacenter);
        
        log.info("Traffic switched to datacenter: {}", activeDatacenter);
    }
}
```

#### 异地多活架构

```java
/**
 * 异地多活容灾服务
 * 实现跨地域的多活部署
 */
@Service
@Slf4j
public class GeographicMultiActiveDisasterRecoveryService {
    
    @Autowired
    private GlobalDataSyncService globalDataSyncService;
    
    @Autowired
    private GeoDNSService geoDNSService;
    
    @Autowired
    private ConflictResolutionService conflictResolutionService;
    
    /**
     * 初始化异地多活架构
     */
    public void initializeGeoMultiActive() {
        log.info("Initializing geographic multi-active disaster recovery");
        
        // 1. 配置全球数据同步
        setupGlobalDataSync();
        
        // 2. 配置地理DNS
        setupGeographicDNS();
        
        // 3. 配置冲突解决机制
        setupConflictResolution();
        
        // 4. 配置数据一致性检查
        setupDataConsistencyCheck();
        
        log.info("Geographic multi-active disaster recovery initialized");
    }
    
    /**
     * 配置全球数据同步
     */
    private void setupGlobalDataSync() {
        List<String> regions = Arrays.asList("asia-east", "europe-west", "us-central");
        
        // 配置异步数据复制
        globalDataSyncService.setupAsyncReplication(regions);
        
        // 配置关键数据的同步复制
        globalDataSyncService.setupSyncReplicationForCriticalData(regions);
        
        // 配置数据分片策略
        globalDataSyncService.setupDataSharding("user_region_based");
    }
    
    /**
     * 处理区域故障
     */
    public void handleRegionFailure(String failedRegion) {
        log.error("Region failure detected: {}", failedRegion);
        
        List<String> healthyRegions = getHealthyRegions();
        healthyRegions.remove(failedRegion);
        
        // 1. 更新GeoDNS配置
        geoDNSService.removeRegionFromDNS(failedRegion);
        geoDNSService.redistributeTraffic(healthyRegions);
        
        // 2. 重新分配数据分片
        globalDataSyncService.redistributeShards(failedRegion, healthyRegions);
        
        // 3. 启动数据恢复流程
        startDataRecoveryProcess(failedRegion, healthyRegions);
        
        log.info("Region failover completed, traffic redistributed to: {}", healthyRegions);
    }
}
```

### 2. 备份恢复策略

```java
/**
 * 备份恢复服务
 * 实现数据备份和恢复策略
 */
@Service
@Slf4j
public class BackupRecoveryService {
    
    @Autowired
    private DatabaseBackupService databaseBackupService;
    
    @Autowired
    private FileBackupService fileBackupService;
    
    @Autowired
    private ConfigBackupService configBackupService;
    
    /**
     * 执行全量备份
     */
    @Scheduled(cron = "0 0 2 * * ?") // 每天凌晨2点执行
    public void performFullBackup() {
        log.info("Starting full backup process");
        
        try {
            String backupId = "FULL_" + LocalDateTime.now().format(DateTimeFormatter.ofPattern("yyyyMMdd_HHmmss"));
            
            // 1. 数据库全量备份
            BackupResult dbBackup = databaseBackupService.performFullBackup(backupId);
            
            // 2. 文件系统备份
            BackupResult fileBackup = fileBackupService.performFullBackup(backupId);
            
            // 3. 配置文件备份
            BackupResult configBackup = configBackupService.performFullBackup(backupId);
            
            // 4. 验证备份完整性
            boolean isValid = validateBackupIntegrity(backupId, 
                Arrays.asList(dbBackup, fileBackup, configBackup));
            
            if (isValid) {
                log.info("Full backup completed successfully: {}", backupId);
                // 清理过期备份
                cleanupExpiredBackups();
            } else {
                log.error("Full backup validation failed: {}", backupId);
                alertService.sendBackupFailureAlert(backupId);
            }
            
        } catch (Exception e) {
            log.error("Full backup failed", e);
            alertService.sendBackupFailureAlert("FULL_BACKUP_ERROR");
        }
    }
    
    /**
     * 执行增量备份
     */
    @Scheduled(cron = "0 0 */4 * * ?") // 每4小时执行一次
    public void performIncrementalBackup() {
        log.info("Starting incremental backup process");
        
        try {
            String backupId = "INCR_" + LocalDateTime.now().format(DateTimeFormatter.ofPattern("yyyyMMdd_HHmmss"));
            
            // 获取上次备份时间
            LocalDateTime lastBackupTime = getLastBackupTime();
            
            // 1. 数据库增量备份
            BackupResult dbBackup = databaseBackupService.performIncrementalBackup(backupId, lastBackupTime);
            
            // 2. 文件系统增量备份
            BackupResult fileBackup = fileBackupService.performIncrementalBackup(backupId, lastBackupTime);
            
            // 3. 配置变更备份
            BackupResult configBackup = configBackupService.performIncrementalBackup(backupId, lastBackupTime);
            
            log.info("Incremental backup completed: {}", backupId);
            
        } catch (Exception e) {
            log.error("Incremental backup failed", e);
            alertService.sendBackupFailureAlert("INCREMENTAL_BACKUP_ERROR");
        }
    }
    
    /**
     * 执行数据恢复
     */
    public RecoveryResult performDataRecovery(String backupId, RecoveryOptions options) {
        log.info("Starting data recovery from backup: {}", backupId);
        
        RecoveryResult result = new RecoveryResult();
        result.setBackupId(backupId);
        result.setStartTime(LocalDateTime.now());
        
        try {
            // 1. 验证备份可用性
            if (!validateBackupAvailability(backupId)) {
                throw new RuntimeException("Backup not available: " + backupId);
            }
            
            // 2. 停止相关服务
            if (options.isStopServices()) {
                stopRelatedServices();
            }
            
            // 3. 恢复数据库
            if (options.isRecoverDatabase()) {
                RecoveryResult dbResult = databaseBackupService.recoverFromBackup(backupId, options);
                result.setDatabaseRecoveryResult(dbResult);
            }
            
            // 4. 恢复文件系统
            if (options.isRecoverFiles()) {
                RecoveryResult fileResult = fileBackupService.recoverFromBackup(backupId, options);
                result.setFileRecoveryResult(fileResult);
            }
            
            // 5. 恢复配置
            if (options.isRecoverConfig()) {
                RecoveryResult configResult = configBackupService.recoverFromBackup(backupId, options);
                result.setConfigRecoveryResult(configResult);
            }
            
            // 6. 验证恢复结果
            boolean isValid = validateRecoveryResult(result);
            result.setSuccess(isValid);
            
            // 7. 重启服务
            if (options.isStopServices() && isValid) {
                startRelatedServices();
            }
            
            result.setEndTime(LocalDateTime.now());
            log.info("Data recovery completed: {}, success: {}", backupId, isValid);
            
        } catch (Exception e) {
            log.error("Data recovery failed for backup: {}", backupId, e);
            result.setSuccess(false);
            result.setErrorMessage(e.getMessage());
            result.setEndTime(LocalDateTime.now());
        }
        
        return result;
    }
    
    /**
     * 执行时点恢复 (Point-in-Time Recovery)
     */
    public RecoveryResult performPointInTimeRecovery(LocalDateTime targetTime, RecoveryOptions options) {
        log.info("Starting point-in-time recovery to: {}", targetTime);
        
        try {
            // 1. 找到最近的全量备份
            String baseBackupId = findNearestFullBackup(targetTime);
            
            // 2. 找到需要应用的增量备份
            List<String> incrementalBackups = findIncrementalBackupsAfter(baseBackupId, targetTime);
            
            // 3. 恢复基础备份
            RecoveryResult baseResult = performDataRecovery(baseBackupId, options);
            
            if (!baseResult.isSuccess()) {
                throw new RuntimeException("Base backup recovery failed");
            }
            
            // 4. 应用增量备份
            for (String incrementalBackup : incrementalBackups) {
                applyIncrementalBackup(incrementalBackup, targetTime);
            }
            
            // 5. 应用事务日志到目标时间点
            applyTransactionLogsToTime(targetTime);
            
            log.info("Point-in-time recovery completed to: {}", targetTime);
            return baseResult;
            
        } catch (Exception e) {
            log.error("Point-in-time recovery failed", e);
            throw new RuntimeException("Point-in-time recovery failed", e);
        }
    }
    
    // 辅助方法实现...
    private boolean validateBackupIntegrity(String backupId, List<BackupResult> backupResults) {
        // 实现备份完整性验证逻辑
        return true;
    }
    
    private void cleanupExpiredBackups() {
        // 实现过期备份清理逻辑
    }
    
    private LocalDateTime getLastBackupTime() {
        // 获取最后备份时间
        return LocalDateTime.now().minusHours(4);
    }
}
```

## 高可用架构部署Demo

### 1. Kubernetes高可用集群部署

```bash
#!/bin/bash
# 高可用Kubernetes集群部署脚本

echo "=== NSRS高可用Kubernetes集群部署 ==="

# 1. 创建命名空间
echo "创建高可用命名空间..."
kubectl create namespace nsrs-ha
kubectl label namespace nsrs-ha istio-injection=enabled

# 2. 部署etcd集群 (高可用)
echo "部署etcd高可用集群..."
cat <<EOF | kubectl apply -f -
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: etcd-cluster
  namespace: nsrs-ha
spec:
  serviceName: etcd-cluster
  replicas: 3
  selector:
    matchLabels:
      app: etcd
  template:
    metadata:
      labels:
        app: etcd
    spec:
      containers:
      - name: etcd
        image: quay.io/coreos/etcd:v3.5.0
        ports:
        - containerPort: 2379
          name: client
        - containerPort: 2380
          name: peer
        env:
        - name: ETCD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: ETCD_INITIAL_CLUSTER
          value: "etcd-cluster-0=http://etcd-cluster-0.etcd-cluster:2380,etcd-cluster-1=http://etcd-cluster-1.etcd-cluster:2380,etcd-cluster-2=http://etcd-cluster-2.etcd-cluster:2380"
        - name: ETCD_INITIAL_CLUSTER_STATE
          value: "new"
        - name: ETCD_INITIAL_CLUSTER_TOKEN
          value: "nsrs-etcd-cluster"
        - name: ETCD_LISTEN_CLIENT_URLS
          value: "http://0.0.0.0:2379"
        - name: ETCD_ADVERTISE_CLIENT_URLS
          value: "http://\$(ETCD_NAME).etcd-cluster:2379"
        - name: ETCD_LISTEN_PEER_URLS
          value: "http://0.0.0.0:2380"
        - name: ETCD_INITIAL_ADVERTISE_PEER_URLS
          value: "http://\$(ETCD_NAME).etcd-cluster:2380"
        volumeMounts:
        - name: etcd-data
          mountPath: /etcd-data
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "1Gi"
            cpu: "1000m"
  volumeClaimTemplates:
  - metadata:
      name: etcd-data
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 10Gi
---
apiVersion: v1
kind: Service
metadata:
  name: etcd-cluster
  namespace: nsrs-ha
spec:
  clusterIP: None
  selector:
    app: etcd
  ports:
  - port: 2379
    name: client
  - port: 2380
    name: peer
EOF

# 3. 部署MySQL主从集群
echo "部署MySQL主从高可用集群..."
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: ConfigMap
metadata:
  name: mysql-config
  namespace: nsrs-ha
data:
  master.cnf: |
    [mysqld]
    log-bin=mysql-bin
    server-id=1
    binlog-format=ROW
    gtid-mode=ON
    enforce-gtid-consistency=ON
    log-slave-updates=ON
    read-only=OFF
  slave.cnf: |
    [mysqld]
    server-id=2
    read-only=ON
    log-bin=mysql-bin
    binlog-format=ROW
    gtid-mode=ON
    enforce-gtid-consistency=ON
    log-slave-updates=ON
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: mysql-master
  namespace: nsrs-ha
spec:
  serviceName: mysql-master
  replicas: 1
  selector:
    matchLabels:
      app: mysql-master
  template:
    metadata:
      labels:
        app: mysql-master
    spec:
      containers:
      - name: mysql
        image: mysql:8.0
        env:
        - name: MYSQL_ROOT_PASSWORD
          valueFrom:
            secretKeyRef:
              name: mysql-secret
              key: root-password
        - name: MYSQL_DATABASE
          value: "nsrs"
        - name: MYSQL_USER
          value: "nsrs_user"
        - name: MYSQL_PASSWORD
          valueFrom:
            secretKeyRef:
              name: mysql-secret
              key: user-password
        ports:
        - containerPort: 3306
        volumeMounts:
        - name: mysql-data
          mountPath: /var/lib/mysql
        - name: mysql-config
          mountPath: /etc/mysql/conf.d/mysql.cnf
          subPath: master.cnf
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
        livenessProbe:
          exec:
            command:
            - mysqladmin
            - ping
            - -h
            - localhost
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          exec:
            command:
            - mysql
            - -h
            - localhost
            - -e
            - "SELECT 1"
          initialDelaySeconds: 5
          periodSeconds: 2
      volumes:
      - name: mysql-config
        configMap:
          name: mysql-config
  volumeClaimTemplates:
  - metadata:
      name: mysql-data
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 50Gi
EOF

# 4. 部署Redis Sentinel高可用集群
echo "部署Redis Sentinel高可用集群..."
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: ConfigMap
metadata:
  name: redis-config
  namespace: nsrs-ha
data:
  redis.conf: |
    bind 0.0.0.0
    port 6379
    tcp-backlog 511
    timeout 0
    tcp-keepalive 300
    daemonize no
    supervised no
    pidfile /var/run/redis_6379.pid
    loglevel notice
    databases 16
    save 900 1
    save 300 10
    save 60 10000
    stop-writes-on-bgsave-error yes
    rdbcompression yes
    rdbchecksum yes
    dbfilename dump.rdb
    dir /data
    maxmemory 1gb
    maxmemory-policy allkeys-lru
  sentinel.conf: |
    bind 0.0.0.0
    port 26379
    sentinel monitor mymaster redis-master 6379 2
    sentinel down-after-milliseconds mymaster 5000
    sentinel parallel-syncs mymaster 1
    sentinel failover-timeout mymaster 10000
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: redis-master
  namespace: nsrs-ha
spec:
  serviceName: redis-master
  replicas: 1
  selector:
    matchLabels:
      app: redis-master
  template:
    metadata:
      labels:
        app: redis-master
    spec:
      containers:
      - name: redis
        image: redis:7.0-alpine
        command:
        - redis-server
        - /etc/redis/redis.conf
        ports:
        - containerPort: 6379
        volumeMounts:
        - name: redis-data
          mountPath: /data
        - name: redis-config
          mountPath: /etc/redis
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"
      volumes:
      - name: redis-config
        configMap:
          name: redis-config
  volumeClaimTemplates:
  - metadata:
      name: redis-data
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 10Gi
EOF

# 5. 部署NSRS应用高可用实例
echo "部署NSRS应用高可用实例..."
cat <<EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nsrs-app
  namespace: nsrs-ha
spec:
  replicas: 5
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 2
      maxUnavailable: 1
  selector:
    matchLabels:
      app: nsrs-app
  template:
    metadata:
      labels:
        app: nsrs-app
        version: v1
    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - nsrs-app
              topologyKey: kubernetes.io/hostname
      containers:
      - name: nsrs-app
        image: nsrs/sim-card-mgnt:latest
        ports:
        - containerPort: 8080
        env:
        - name: SPRING_PROFILES_ACTIVE
          value: "prod,ha"
        - name: MYSQL_HOST
          value: "mysql-master"
        - name: REDIS_HOST
          value: "redis-sentinel"
        - name: ETCD_ENDPOINTS
          value: "http://etcd-cluster:2379"
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
        livenessProbe:
          httpGet:
            path: /actuator/health
            port: 8080
          initialDelaySeconds: 60
          periodSeconds: 30
          timeoutSeconds: 10
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /actuator/health/readiness
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        volumeMounts:
        - name: app-config
          mountPath: /app/config
        - name: app-logs
          mountPath: /app/logs
      volumes:
      - name: app-config
        configMap:
          name: nsrs-app-config
      - name: app-logs
        emptyDir: {}
EOF

# 6. 创建负载均衡服务
echo "创建负载均衡服务..."
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: Service
metadata:
  name: nsrs-app-service
  namespace: nsrs-ha
  annotations:
    service.beta.kubernetes.io/aws-load-balancer-type: nlb
    service.beta.kubernetes.io/aws-load-balancer-cross-zone-load-balancing-enabled: "true"
spec:
  type: LoadBalancer
  selector:
    app: nsrs-app
  ports:
  - port: 80
    targetPort: 8080
    protocol: TCP
  sessionAffinity: ClientIP
  sessionAffinityConfig:
    clientIP:
      timeoutSeconds: 3600
EOF

# 7. 配置HPA (Horizontal Pod Autoscaler)
echo "配置水平Pod自动扩缩容..."
cat <<EOF | kubectl apply -f -
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: nsrs-app-hpa
  namespace: nsrs-ha
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: nsrs-app
  minReplicas: 3
  maxReplicas: 20
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 10
        periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60
EOF

# 8. 配置PodDisruptionBudget
echo "配置Pod中断预算..."
cat <<EOF | kubectl apply -f -
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: nsrs-app-pdb
  namespace: nsrs-ha
spec:
  minAvailable: 3
  selector:
    matchLabels:
      app: nsrs-app
EOF

echo "等待部署完成..."
kubectl wait --for=condition=available --timeout=600s deployment/nsrs-app -n nsrs-ha

echo "验证高可用部署状态..."
kubectl get pods -n nsrs-ha -o wide
kubectl get services -n nsrs-ha
kubectl get hpa -n nsrs-ha

echo "=== 高可用Kubernetes集群部署完成 ==="
```

### 2. 故障转移机制Demo

```bash
#!/bin/bash
# 故障转移机制测试脚本

echo "=== NSRS故障转移机制测试 ==="

# 1. 模拟应用实例故障
echo "1. 测试应用实例故障转移..."
echo "删除一个应用Pod模拟故障..."
kubectl delete pod -l app=nsrs-app -n nsrs-ha --field-selector=status.phase=Running | head -1

echo "等待Pod重新调度..."
sleep 30

echo "检查Pod状态:"
kubectl get pods -l app=nsrs-app -n nsrs-ha

echo "检查服务可用性:"
kubectl get endpoints nsrs-app-service -n nsrs-ha

# 2. 模拟数据库故障
echo "\n2. 测试数据库故障转移..."
echo "停止MySQL主节点..."
kubectl scale statefulset mysql-master --replicas=0 -n nsrs-ha

echo "等待30秒..."
sleep 30

echo "启动MySQL从节点作为新主节点..."
kubectl scale statefulset mysql-slave --replicas=1 -n nsrs-ha

echo "更新应用配置指向新的数据库主节点..."
kubectl patch deployment nsrs-app -n nsrs-ha -p '{
  "spec": {
    "template": {
      "spec": {
        "containers": [{
          "name": "nsrs-app",
          "env": [{
            "name": "MYSQL_HOST",
            "value": "mysql-slave"
          }]
        }]
      }
    }
  }
}'

echo "等待应用重启..."
kubectl rollout status deployment/nsrs-app -n nsrs-ha

# 3. 模拟Redis故障
echo "\n3. 测试Redis故障转移..."
echo "停止Redis主节点..."
kubectl scale statefulset redis-master --replicas=0 -n nsrs-ha

echo "等待Sentinel检测故障并切换..."
sleep 60

echo "检查Redis Sentinel状态:"
kubectl exec -it redis-sentinel-0 -n nsrs-ha -- redis-cli -p 26379 sentinel masters

# 4. 模拟网络分区
echo "\n4. 测试网络分区故障..."
echo "创建网络策略模拟分区..."
cat <<EOF | kubectl apply -f -
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: simulate-partition
  namespace: nsrs-ha
spec:
  podSelector:
    matchLabels:
      app: nsrs-app
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: nsrs-app
  egress:
  - to:
    - podSelector:
        matchLabels:
          app: nsrs-app
EOF

echo "等待30秒观察影响..."
sleep 30

echo "检查应用健康状态:"
kubectl get pods -l app=nsrs-app -n nsrs-ha

echo "删除网络策略恢复连接..."
kubectl delete networkpolicy simulate-partition -n nsrs-ha

# 5. 测试自动扩缩容
echo "\n5. 测试自动扩缩容..."
echo "生成负载测试流量..."
kubectl run load-generator --image=busybox --restart=Never -n nsrs-ha -- /bin/sh -c "while true; do wget -q -O- http://nsrs-app-service/actuator/health; done"

echo "等待2分钟观察扩容..."
sleep 120

echo "检查HPA状态:"
kubectl get hpa nsrs-app-hpa -n nsrs-ha

echo "检查Pod数量变化:"
kubectl get pods -l app=nsrs-app -n nsrs-ha

echo "停止负载生成器..."
kubectl delete pod load-generator -n nsrs-ha

echo "等待2分钟观察缩容..."
sleep 120

echo "再次检查Pod数量:"
kubectl get pods -l app=nsrs-app -n nsrs-ha

# 6. 测试跨可用区故障转移
echo "\n6. 测试跨可用区故障转移..."
echo "获取当前Pod分布:"
kubectl get pods -l app=nsrs-app -n nsrs-ha -o wide

echo "模拟可用区故障 - 驱逐特定节点上的Pod..."
NODE=$(kubectl get pods -l app=nsrs-app -n nsrs-ha -o jsonpath='{.items[0].spec.nodeName}')
echo "驱逐节点 $NODE 上的Pod..."
kubectl drain $NODE --ignore-daemonsets --delete-emptydir-data --force

echo "等待Pod重新调度到其他节点..."
sleep 60

echo "检查新的Pod分布:"
kubectl get pods -l app=nsrs-app -n nsrs-ha -o wide

echo "恢复节点:"
kubectl uncordon $NODE

echo "=== 故障转移机制测试完成 ==="
```

### 3. 容灾演练脚本

```bash
#!/bin/bash
# 容灾演练脚本

echo "=== NSRS容灾演练 ==="

# 1. 数据中心故障演练
echo "1. 模拟数据中心A故障..."

# 标记数据中心A的所有节点为不可调度
echo "标记数据中心A节点为不可调度..."
kubectl get nodes -l zone=datacenter-a -o name | xargs kubectl cordon

# 驱逐数据中心A的所有Pod
echo "驱逐数据中心A的所有Pod..."
kubectl get nodes -l zone=datacenter-a -o name | xargs -I {} kubectl drain {} --ignore-daemonsets --delete-emptydir-data --force

echo "等待Pod重新调度到数据中心B..."
sleep 120

echo "检查Pod分布:"
kubectl get pods -n nsrs-ha -o wide

# 2. 数据库主从切换演练
echo "\n2. 数据库主从切换演练..."

# 创建数据库切换脚本
cat <<'EOF' > /tmp/db_failover.sh
#!/bin/bash
echo "开始数据库主从切换..."

# 停止主数据库写入
echo "设置主数据库为只读..."
kubectl exec mysql-master-0 -n nsrs-ha -- mysql -u root -p$MYSQL_ROOT_PASSWORD -e "SET GLOBAL read_only = ON;"

# 等待从数据库同步完成
echo "等待从数据库同步..."
sleep 30

# 提升从数据库为主数据库
echo "提升从数据库为主数据库..."
kubectl exec mysql-slave-0 -n nsrs-ha -- mysql -u root -p$MYSQL_ROOT_PASSWORD -e "STOP SLAVE; RESET SLAVE ALL; SET GLOBAL read_only = OFF;"

# 更新应用配置
echo "更新应用数据库连接配置..."
kubectl patch configmap nsrs-app-config -n nsrs-ha --patch '{
  "data": {
    "database.host": "mysql-slave",
    "database.port": "3306"
  }
}'

# 重启应用以应用新配置
echo "重启应用实例..."
kubectl rollout restart deployment/nsrs-app -n nsrs-ha
kubectl rollout status deployment/nsrs-app -n nsrs-ha

echo "数据库主从切换完成"
EOF

chmod +x /tmp/db_failover.sh
/tmp/db_failover.sh

# 3. 备份恢复演练
echo "\n3. 备份恢复演练..."

# 创建测试数据
echo "创建测试数据..."
kubectl exec mysql-slave-0 -n nsrs-ha -- mysql -u root -p$MYSQL_ROOT_PASSWORD nsrs -e "
INSERT INTO sim_card (iccid, imsi, msisdn, status) VALUES 
('89860000000000000001', '460000000000001', '13800000001', 'ACTIVE'),
('89860000000000000002', '460000000000002', '13800000002', 'ACTIVE');
"

# 执行备份
echo "执行数据库备份..."
BACKUP_FILE="/tmp/nsrs_backup_$(date +%Y%m%d_%H%M%S).sql"
kubectl exec mysql-slave-0 -n nsrs-ha -- mysqldump -u root -p$MYSQL_ROOT_PASSWORD --single-transaction --routines --triggers nsrs > $BACKUP_FILE

echo "备份文件创建: $BACKUP_FILE"

# 模拟数据损坏
echo "模拟数据损坏..."
kubectl exec mysql-slave-0 -n nsrs-ha -- mysql -u root -p$MYSQL_ROOT_PASSWORD nsrs -e "DELETE FROM sim_card WHERE iccid LIKE '89860000000000000%';"

echo "验证数据损坏:"
kubectl exec mysql-slave-0 -n nsrs-ha -- mysql -u root -p$MYSQL_ROOT_PASSWORD nsrs -e "SELECT COUNT(*) as remaining_records FROM sim_card;"

# 执行数据恢复
echo "执行数据恢复..."
kubectl exec -i mysql-slave-0 -n nsrs-ha -- mysql -u root -p$MYSQL_ROOT_PASSWORD nsrs < $BACKUP_FILE

echo "验证数据恢复:"
kubectl exec mysql-slave-0 -n nsrs-ha -- mysql -u root -p$MYSQL_ROOT_PASSWORD nsrs -e "SELECT COUNT(*) as recovered_records FROM sim_card;"

# 4. 网络故障演练
echo "\n4. 网络故障演练..."

# 模拟网络延迟
echo "模拟网络延迟..."
cat <<EOF | kubectl apply -f -
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: simulate-latency
  namespace: nsrs-ha
spec:
  podSelector:
    matchLabels:
      app: nsrs-app
  policyTypes:
  - Egress
  egress:
  - to: []
    ports:
    - protocol: TCP
      port: 3306
    - protocol: TCP
      port: 6379
EOF

echo "等待30秒观察应用响应..."
sleep 30

echo "检查应用健康状态:"
kubectl get pods -l app=nsrs-app -n nsrs-ha

echo "移除网络限制..."
kubectl delete networkpolicy simulate-latency -n nsrs-ha

# 5. 恢复数据中心A
echo "\n5. 恢复数据中心A..."
echo "恢复数据中心A节点可调度状态..."
kubectl get nodes -l zone=datacenter-a -o name | xargs kubectl uncordon

echo "等待负载重新平衡..."
sleep 60

echo "检查最终Pod分布:"
kubectl get pods -n nsrs-ha -o wide

echo "=== 容灾演练完成 ==="

# 6. 生成演练报告
echo "\n6. 生成演练报告..."
cat <<EOF > /tmp/disaster_recovery_report.md
# NSRS容灾演练报告

## 演练时间
$(date)

## 演练项目
1. 数据中心故障切换
2. 数据库主从切换
3. 备份恢复测试
4. 网络故障处理
5. 系统恢复验证

## 演练结果
### 数据中心故障切换
- 故障检测时间: < 30秒
- 流量切换时间: < 2分钟
- 数据丢失: 无
- 服务中断时间: < 2分钟

### 数据库主从切换
- 切换时间: < 1分钟
- 数据一致性: 正常
- 应用重连: 自动

### 备份恢复
- 备份完整性: 验证通过
- 恢复时间: < 5分钟
- 数据完整性: 100%

### 网络故障处理
- 故障检测: 自动
- 降级策略: 生效
- 恢复时间: < 1分钟

## 改进建议
1. 优化故障检测机制，缩短检测时间
2. 完善自动化切换流程
3. 加强监控告警覆盖
4. 定期进行演练验证

## 总体评估
演练成功，系统高可用机制运行正常。
EOF

echo "演练报告已生成: /tmp/disaster_recovery_report.md"
cat /tmp/disaster_recovery_report.md
```

## 高可用架构最佳实践

### 1. 设计原则

#### 无单点故障 (No Single Point of Failure)
- **数据库层**: 采用主从复制、读写分离
- **应用层**: 多实例部署、负载均衡
- **缓存层**: Redis Sentinel或Cluster模式
- **网络层**: 多路径、冗余连接

#### 故障隔离 (Failure Isolation)
- **服务隔离**: 微服务架构，服务间解耦
- **资源隔离**: 容器化部署，资源限制
- **网络隔离**: 网络分段，安全组策略
- **数据隔离**: 分库分表，数据分片

#### 快速恢复 (Fast Recovery)
- **健康检查**: 实时监控，快速故障检测
- **自动切换**: 自动故障转移机制
- **预热机制**: 实例预热，减少冷启动时间
- **回滚策略**: 快速回滚到稳定版本

### 2. 监控告警策略

#### 基础设施监控
```yaml
# Prometheus监控配置
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: nsrs-ha
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      evaluation_interval: 15s
    
    rule_files:
      - "nsrs_alerts.yml"
    
    scrape_configs:
      # Kubernetes API Server
      - job_name: 'kubernetes-apiservers'
        kubernetes_sd_configs:
        - role: endpoints
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        relabel_configs:
        - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
          action: keep
          regex: default;kubernetes;https
      
      # Node Exporter
      - job_name: 'kubernetes-nodes'
        kubernetes_sd_configs:
        - role: node
        relabel_configs:
        - action: labelmap
          regex: __meta_kubernetes_node_label_(.+)
        - target_label: __address__
          replacement: kubernetes.default.svc:443
        - source_labels: [__meta_kubernetes_node_name]
          regex: (.+)
          target_label: __metrics_path__
          replacement: /api/v1/nodes/${1}/proxy/metrics
      
      # NSRS Application
      - job_name: 'nsrs-app'
        kubernetes_sd_configs:
        - role: endpoints
          namespaces:
            names:
            - nsrs-ha
        relabel_configs:
        - source_labels: [__meta_kubernetes_service_name]
          action: keep
          regex: nsrs-app-service
        - source_labels: [__meta_kubernetes_endpoint_port_name]
          action: keep
          regex: http
        - source_labels: [__address__]
          target_label: __address__
          regex: ([^:]+)(?::\d+)?
          replacement: ${1}:8080
        - target_label: __metrics_path__
          replacement: /actuator/prometheus
      
      # MySQL
      - job_name: 'mysql'
        static_configs:
        - targets: ['mysql-master:9104', 'mysql-slave:9104']
      
      # Redis
      - job_name: 'redis'
        static_configs:
        - targets: ['redis-master:9121', 'redis-sentinel:9121']
  
  nsrs_alerts.yml: |
    groups:
    - name: nsrs.rules
      rules:
      # 应用可用性告警
      - alert: NSRSApplicationDown
        expr: up{job="nsrs-app"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "NSRS应用实例不可用"
          description: "NSRS应用实例 {{ $labels.instance }} 已经下线超过1分钟"
      
      # 高错误率告警
      - alert: NSRSHighErrorRate
        expr: rate(http_requests_total{job="nsrs-app",status=~"5.."}[5m]) > 0.1
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "NSRS应用错误率过高"
          description: "NSRS应用 {{ $labels.instance }} 错误率超过10%"
      
      # 响应时间告警
      - alert: NSRSHighLatency
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket{job="nsrs-app"}[5m])) > 2
        for: 3m
        labels:
          severity: warning
        annotations:
          summary: "NSRS应用响应时间过长"
          description: "NSRS应用 {{ $labels.instance }} 95%响应时间超过2秒"
      
      # 数据库连接告警
      - alert: MySQLDown
        expr: mysql_up == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "MySQL数据库不可用"
          description: "MySQL实例 {{ $labels.instance }} 不可用"
      
      # Redis连接告警
      - alert: RedisDown
        expr: redis_up == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Redis缓存不可用"
          description: "Redis实例 {{ $labels.instance }} 不可用"
      
      # 资源使用率告警
      - alert: HighCPUUsage
        expr: (100 - (avg by (instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)) > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "节点CPU使用率过高"
          description: "节点 {{ $labels.instance }} CPU使用率超过80%"
      
      - alert: HighMemoryUsage
        expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 85
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "节点内存使用率过高"
          description: "节点 {{ $labels.instance }} 内存使用率超过85%"
      
      # 磁盘空间告警
      - alert: HighDiskUsage
        expr: (1 - (node_filesystem_avail_bytes / node_filesystem_size_bytes)) * 100 > 90
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "节点磁盘空间不足"
          description: "节点 {{ $labels.instance }} 磁盘使用率超过90%"
```

### 3. 性能优化建议

#### 应用层优化
- **连接池优化**: 合理配置数据库连接池大小
- **缓存策略**: 多级缓存，减少数据库压力
- **异步处理**: 非关键业务异步化处理
- **限流熔断**: 实现服务限流和熔断机制

#### 数据库优化
- **读写分离**: 读操作分散到从库
- **分库分表**: 大表拆分，提高查询性能
- **索引优化**: 合理创建和维护索引
- **查询优化**: SQL语句优化，避免慢查询

#### 网络优化
- **CDN加速**: 静态资源CDN分发
- **负载均衡**: 智能负载均衡算法
- **网络优化**: 减少网络跳数，优化路由
- **压缩传输**: 启用数据压缩传输

### 4. 安全加固措施

#### 网络安全
- **网络隔离**: VPC、安全组配置
- **防火墙**: 入站出站规则限制
- **DDoS防护**: 流量清洗，攻击防护
- **SSL/TLS**: 数据传输加密

#### 应用安全
- **身份认证**: 多因子认证机制
- **权限控制**: RBAC权限模型
- **数据加密**: 敏感数据加密存储
- **安全审计**: 操作日志审计

#### 运维安全
- **访问控制**: 堡垒机访问控制
- **密钥管理**: 密钥轮换机制
- **漏洞扫描**: 定期安全扫描
- **应急响应**: 安全事件响应流程

### 5. 容量规划指导

#### 性能基准测试
```bash
#!/bin/bash
# 性能基准测试脚本

echo "=== NSRS性能基准测试 ==="

# 1. 数据库性能测试
echo "1. 数据库性能测试..."
sysbench --db-driver=mysql --mysql-host=mysql-master --mysql-port=3306 \
         --mysql-user=nsrs_user --mysql-password=password --mysql-db=nsrs \
         --table-size=100000 --tables=10 --threads=16 --time=300 \
         oltp_read_write prepare

sysbench --db-driver=mysql --mysql-host=mysql-master --mysql-port=3306 \
         --mysql-user=nsrs_user --mysql-password=password --mysql-db=nsrs \
         --table-size=100000 --tables=10 --threads=16 --time=300 \
         --report-interval=10 oltp_read_write run

# 2. 应用性能测试
echo "\n2. 应用性能测试..."
ab -n 10000 -c 100 -k http://nsrs-app-service/api/sim-cards

# 3. Redis性能测试
echo "\n3. Redis性能测试..."
redis-benchmark -h redis-master -p 6379 -n 100000 -c 50 -d 1024

echo "=== 性能基准测试完成 ==="
```

#### 容量规划建议
- **CPU**: 预留30%的CPU资源用于突发流量
- **内存**: 预留25%的内存资源，避免OOM
- **存储**: 预留40%的存储空间，支持数据增长
- **网络**: 预留50%的网络带宽，应对流量峰值

通过以上高可用架构设计和实施，NSRS号卡资源管理系统能够在各种故障场景下保持服务的连续性和数据的完整性，满足电信级系统的高可用性要求。
```